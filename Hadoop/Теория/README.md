# Содержание

-[Архитектура экосистемы Hadoop](#Архитектура-экосистемы-Hadoop)

-[Архитектура HDFS](#Архитектура-HDFS)

**Hadoop** — это популярная платформа с открытым исходным кодом, которая используется для хранения и обработки больших объемов данных.
Она была разработана для того, чтобы работать на кластерах серверов, обеспечивая эффективное распределение и обработку данных между множеством машин. 
Hadoop играет ключевую роль в экосистеме Big Data и используется для анализа огромных наборов данных в различных областях, таких как анализ логов, машинное обучение и бизнес-аналитика.

<img width="2000" height="473" alt="image" src="https://github.com/user-attachments/assets/f0fa8bbd-6ef1-4a36-a691-e00a8c0598d3" />


## Архитектура экосистемы Hadoop

**Экосистема состоит из четырёх ключевых компонентов:** `HDFS`, `YARN`, `MapReduce` и `Common`. 
В дополнение к ним выпущено несколько десятков инструментов, используемых для расширения функциональности платформы.

**1. Hadoop Distributed File System (HDFS):**

HDFS — это распределённая файловая система, которая позволяет хранить большие объемы данных на множестве машин. 
Она разбивает данные на блоки и распределяет их между узлами кластера, обеспечивая как высокую надёжность (данные дублируются), так и масштабируемость.

**2. MapReduce:**

Это фреймворк, программная модель для распределённой обработки данных хранящихся в `HDFS`. `MapReduce` состоит из двух этапов:
 
 - **Map:** данные разбиваются на небольшие части и обрабатываются параллельно.

 - **Reduce:** результаты обработки собираются и объединяются.

**3. YARN (Yet Another Resource Negotiator):**

YARN — это система управления ресурсами Hadoop. Она распределяет ресурсы между различными приложениями и задачами, что делает Hadoop более гибким и способным поддерживать несколько рабочих нагрузок одновременно.

YARN позволяет разным приложениям (не только MapReduce) использовать ресурсы Hadoop.

**4. Hadoop Common:**

Это набор общих библиотек и утилит, которые поддерживают работу всех компонентов Hadoop. Они обеспечивают взаимодействие между различными частями системы.

<p align="center"><img width="500" height="490" alt="Без названия" src="https://github.com/user-attachments/assets/4cf69dee-62dc-400a-ac2d-c48d09c9c464" /></p>

## Архитектура HDFS

**«Узел», или нода (от англ. node — «узел»)** - эти понятия идентичны и обозначают серверный компьютер с вычислительной мощностью, которую можно использовать для выполнения полезной работы.

Много узлов — нод, компьютеров — можно связать в сеть, которую называют **кластер**.

Классический кластер в дата-центре выглядит как высокая стойка с большим количеством серверных компьютеров — узлов.

Кластер намного мощнее одиночного компьютера. Соответственно, может выполнять более сложные задачи, например обрабатывать массивы информации и файлы, которые не помещаются в оперативную память одиночного компьютера.

В кластере (группе компьютеров, соединённых в единую сеть), на котором выполняются вычисления, есть два вида узлов, то есть серверов, компьютеров:

- **Главный узел**, который также называют `master node` или `master`.
- **Рабочий узел**, он же `worker node`, или просто `worker`.

**Архитектура `Hadoop Distributed File System (HDFS)`** состоит из нескольких ключевых компонентов, которые работают вместе для обеспечения распределенного хранения и обработки данных в кластере `Hadoop`. Вот основные компоненты и принципы архитектуры `HDFS`:

**1. NameNode (узел имени):**

- `NameNode` является главным узлом метаданных в `HDFS`.
- Не хранит сами данные (только карта).
- Он хранит информацию о том, где расположены блоки данных в файловой системе, и о состоянии файлов и каталогов.
- 'NameNode' также отслеживает работу 'DataNode' и координирует операции записи, чтения и удаления файлов.
- Вся метаинформация о файлах и блоках данных хранится в оперативной памяти 'NameNode` и, поэтому, она должна быть достаточно емкой для обработки больших объемов данных.
- `NameNode` напрямую к `DataNode` никогда не обращается, все идет через `ClientNode`.
- 
**2. DataNode (узел данных):**

- `DataNode` представляет собой узел хранения фактических блоков данных.
- Каждый блок обычно имеет несколько копий (репликация, стандартно = 3).
- Он хранит блоки данных на локальных дисках и отвечает за чтение и запись данных по запросу `NameNode` и клиентов.
- `DataNode` периодически отправляет отчеты о своем состоянии `NameNode`, сообщая ему о доступности блоков данных.

**3. Secondary NameNode (вторичный узел имени):**

- `Secondary NameNode` предназначен для обслуживания `NameNode` и выполнения операций по резервному копированию и слиянию журналов транзакций.
- Вторичный узел имени не является резервным узлом для `NameNode`. Он просто помогает восстановлению системы после сбоев и выполняет процедуры слияния и архивирования, чтобы уменьшить время восстановления в случае необходимости.
- Вторичный узел — как и `NameNode`, это отдельный компьютер в кластере. Вторичный узел копирует образ `HDFS` и лог транзакций (операций с файловыми блоками) во временную папку, применяет изменения, накопленные в логе транзакций к образу `HDFS`, а также записывает его на узел `NameNode` и очищает лог транзакций. `Secondary NameNode` необходим, чтобы вручную быстро восстановить `NameNode` в случае его выхода из строя.

**4. Client (клиент):**

- Клиенты представляют собой приложения, которые используют `HDFS` для чтения, записи и обработки данных.
- Клиенты отправляют запросы на операции файловой системы (например, чтение файла) к `NameNode` и затем взаимодействуют с `DataNode` для фактического доступа к данным.

**5. Block (блок):**

- Данные в `HDFS` разделены на блоки фиксированного размера (обычно 64 МБ по умолчанию).
- Блоки данных реплицируются на разные узлы данных для обеспечения отказоустойчивости и достижения высокой доступности данных.

**Кратко:**

Сервер имён, или *NameNode*, оперирует всей метаинформацией о хранимых данных.

*Secondary NameNode* - Вторичный узел помогает восстановить *NameNode*.

*DataNode* - Именно этот узел создаёт, копирует и удаляет блоки, обрабатывает запросы на чтение и запись, а также сообщает *NameNode* о своём состоянии.

Клиент хочет прочитать файл. Обращается к `NameNode` → получает список `DataNode`, где лежат блоки.

Клиент читает блоки напрямую с `DataNode` (минует `NameNode`, чтобы не перегружать его).

Если `DataNode` падает → клиент переключается на другую реплику.

<p align="center"><img width="400" height="300" alt="Без названия (1)" src="https://github.com/user-attachments/assets/b0116f10-f306-406f-b0d2-0add9e8aeb43" /></p>

**Пример**

Например у нас есть excel файл на компьютере, который хранится в какой то папке на рабочем столе. В мире больших данных, один файл делят на несколько блоков.
Размер блока в HDFS можно сделать любым, в основном делят на блоки по 128 мб.

<p align="center"><img width="600" height="300" alt="image" src="https://github.com/user-attachments/assets/2ebed442-52fe-4680-8019-aa121137e23f" /></p>

То есть у нас есть HDD диск, с красной магнитной головкой. Например мы пишем на диск файл размером 100мб одним блоком. Диск напишет одну длинную непрерывную дорожку.
И когда будем считывать этот файл, то эта магнитная головка найдет эту дорожку с файлом и будет считывать эту дорожку с файлом непрерывно за 1 сек.
Если поделить файл на несколько блоков, то магнитная головка будет бегать с одной дорожки на другую. В результате чего чтение будет происходить за 2 сек. И время затраченное на перемещение магнитной головки будет иметь накопительный эффект. Поэтому делить файл на большое количество блоков не разумно. Точно так же не разумно оставлять один блок, так как не всегда читаем весь файл целиком. 
Поэтому оптимально размер блока делать 128 мб.

<p align="center"><img width="600" height="300" alt="image" src="https://github.com/user-attachments/assets/9ce7510e-a716-4fb0-9103-ac8d1445033e" /></p>
