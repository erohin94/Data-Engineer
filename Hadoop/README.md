# Про HDFS

Это распределенная файловая система.

Например у нас есть excel файл на компьютере, который хранится в какой то папке на рабочем столе.

В мире больших данных, один файл делят на несколько блоков.

![image](https://github.com/user-attachments/assets/6e8e6402-0023-4fb6-81a7-7186dc9ccaae)

![image](https://github.com/user-attachments/assets/e14d931f-9de4-47f6-a44f-d76d4b5d6cac)

Размер блока в HDFS можно сделать любым, в основном делят на блоки по 128 мб. 

То есть у нас есть HDD диск, с красной магнитной головкой. Например мы пишем на диск файл размером 100мб одним блоком. Диск напишет одну длинную непрерывную дорожку. 

И когда будем считывать этот файл, то эта магнитная головка найдет эту дорожку с файлом и будет считывать эту дорожку с файлом непрерывно за 1 сек.

Если поделить файл на несколько блоков, то магнитная головка будет бегать с одной дорожки на другую. В результате чего чтение будет происходить за 2 сек. И время затраченное на перемещение магнитной головки будет иметь накопительный эффект.

Поэтому делить файл на большое количество блоков не разумно. Точно так же не разумно оставлять один блок, так как не всегда читаем весь файл целиком. Поэтому оптимально размер блока делать 128 мб.

![image](https://github.com/user-attachments/assets/b8944f41-0654-4b0f-a608-0f02c4e4a6fd)

**Как делить на блоки?**

![image](https://github.com/user-attachments/assets/46040598-5ae7-4d98-af5e-17d3c1f9481b)

![image](https://github.com/user-attachments/assets/f95b95cf-8534-411e-9176-f95b536253e8)

Если файл меньше размера блока HDFS, то блок записывается размером как сам файл.

![image](https://github.com/user-attachments/assets/e56350f7-2464-45f9-bac4-6fb759ee87f3)

**Репликация**

Например, хотим загрузить файл размером 150 Мбайт.

Будем учитывать, что по умолчанию в нашей сборке HDFS стоит фактор репликации - 3,  а размер каждого блока 64 Мб.

1. Разделим наш файл 150 Мбайт на размер блока 64 Мб = получится 2.34375 файлов. Так как количество файлов не может быть неровным, то получится что 2 файла будут с одинаковыми размерами в 64 Мб, а третий файл будет остатком от деления, то есть 22 Мбайт.

2. Исходя из того, что файл был разделен на 3 части, очевидно, что необходимо иметь хотя бы 3 дата ноды. Таким образом 2 файла по 64 Мбайт будут загружены на НОДУ1 и НОДУ2, а на НОДУ3 положится файл размером 22 МБайт.

3. Не будем забывать о том, что HDFS - отказоустойчивая система, и, в случае выхода одной дата ноды, информация все равно должна быть доступна на другой ноде. То есть сейчас оперируем 3 нодами, 3 кусочками файла. То есть схема будет выглядеть следующим образом:

![image](https://github.com/user-attachments/assets/b8ec00f6-ecda-42ae-adec-0af485e23704)

В файловой системе в терминале это выглядит вот так:

![image](https://github.com/user-attachments/assets/871e4473-1c5a-4e32-8de8-3a120c6cec11)

**Архитектура Hadoop Distributed File System (HDFS)**

Архитектура Hadoop Distributed File System (HDFS) состоит из нескольких ключевых компонентов, которые работают вместе для обеспечения распределенного хранения и обработки данных. Вот основные компоненты и принципы архитектуры HDFS:

1. NameNode (узел имени):

NameNode является главным узлом метаданных в HDFS.

Он хранит информацию о том, где расположены блоки данных в файловой системе, и о состоянии файлов и каталогов.

NameNode также отслеживает работу DataNode и координирует операции записи, чтения и удаления файлов.

Вся метаинформация о файлах и блоках данных хранится в оперативной памяти NameNode и, поэтому, она должна быть достаточно емкой для обработки больших объемов данных.

2. DataNode (узел данных):

DataNode представляет собой узел хранения фактических блоков данных.

Он хранит блоки данных на локальных дисках и отвечает за чтение и запись данных по запросу NameNode и клиентов.

DataNode периодически отправляет отчеты о своем состоянии NameNode, сообщая ему о доступности блоков данных.

3. Secondary NameNode (вторичный узел имени):

Secondary NameNode предназначен для обслуживания NameNode и выполнения операций по резервному копированию и слиянию журналов транзакций.

Вторичный узел имени не является резервным узлом для NameNode. Он просто помогает восстановлению системы после сбоев и выполняет процедуры слияния и архивирования, чтобы уменьшить время восстановления в случае необходимости.

4. Client (клиент):
   
Клиенты представляют собой приложения, которые используют HDFS для чтения, записи и обработки данных.

Клиенты отправляют запросы на операции файловой системы (например, чтение файла) к NameNode и затем взаимодействуют с DataNode для фактического доступа к данным.

5. Block (блок):
   
Данные в HDFS разделены на блоки фиксированного размера (обычно 64 МБ по умолчанию).

Блоки данных реплицируются на разные узлы данных для обеспечения отказоустойчивости и достижения высокой доступности данных.

![image](https://github.com/user-attachments/assets/fbe87fd5-279f-4a2e-b8e8-cd7da6e61f89)

![image](https://github.com/user-attachments/assets/9c567b64-dea2-464f-98c2-483baf6019aa)

**Простыми словами:**

NameNode напрямую к DataNode никогда не обращается, все идет через ClientNode.

![image](https://github.com/user-attachments/assets/55531b6c-3d1a-4358-bd7d-98b36b4b1802)

*На клиентской ноде хотим прочитать файл.*

Обращаемся к NameNode. 

NameNode смотрит в свой справочник и отдает адреса для всех реплик сразу, то есть говорит на на первой DataNode, второй DataNode, третьей DataNode такие то блоки от такого то файла которые тебе нужны. Вот держи апишник "шкафчика-стойки-сервака".

ClientNode после того как получила список идет к DataNode и забирает данные с дисков.

![image](https://github.com/user-attachments/assets/62ad90fb-391b-4a44-b0b5-f88db2233f55)

*Запись происходит немного по другому*

Обращаемся к NameNode. Говорим хотим записать файлик размером гигабайт, фактор репликации такой то, размер блока такой то. Приходим на NameNode. NameNode смотрит где есть оптимально близкое расположение к ClientNode, чтобы не писать в соседний город в Дата Центр, ищет место максимально близкое с ClientNode, например соседний сервер. NameNode расчитывает и выдает список адресов куда можно записать блок. ClientNode получает эту инфу(метаданные) и дальше записывает только первую реплику блока. Первую реплику записали, далее ClientNode идет в NameNode и говорит что все ок. Далее DataNode сами реплицируют все оставшиеся блоки и отсылают всю инфу в NameNode через ClientNode.

![image](https://github.com/user-attachments/assets/5d554057-59b3-4cc0-8f6a-2a2eaaa8376a)

В профессиональном сообществе часто используют термин «узел», или нода (от англ. node — «узел»). Эти понятия идентичны и обозначают серверный компьютер с вычислительной мощностью, которую можно использовать для выполнения полезной работы.

Много узлов — нод, компьютеров — можно связать в сеть, которую называют кластер.

Классический кластер в дата-центре выглядит как высокая стойка с большим количеством серверных компьютеров — узлов.

Кластер намного мощнее одиночного компьютера. Соответственно, может выполнять более сложные задачи, например обрабатывать массивы информации и файлы, которые не помещаются в оперативную память одиночного компьютера.

В кластере (группе компьютеров, соединённых в единую сеть), на котором выполняются вычисления, есть два вида узлов, то есть серверов, компьютеров:

Главный узел, который также называют master node или master.

Рабочий узел, он же worker node, или просто worker.
