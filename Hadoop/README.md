# Про HDFS

Это распределенная файловая система.

Например у нас есть excel файл на компьютере, который хранится в какой то папке на рабочем столе.

В мире больших данных, один файл делят на несколько блоков.

![image](https://github.com/user-attachments/assets/6e8e6402-0023-4fb6-81a7-7186dc9ccaae)

![image](https://github.com/user-attachments/assets/e14d931f-9de4-47f6-a44f-d76d4b5d6cac)

Размер блока в HDFS можно сделать любым, в основном делят на блоки по 128 мб. 

То есть у нас есть HDD диск, с красной магнитной головкой. Например мы пишем на диск файл размером 100мб одним блоком. Диск напишет одну длинную непрерывную дорожку. 

И когда будем считывать этот файл, то эта магнитная головка найдет эту дорожку с файлом и будет считывать эту дорожку с файлом непрерывно за 1 сек.

Если поделить файл на несколько блоков, то магнитная головка будет бегать с одной дорожки на другую. В результате чего чтение будет происходить за 2 сек. И время затраченное на перемещение магнитной головки будет иметь накопительный эффект.

Поэтому делить файл на большое количество блоков не разумно. Точно так же не разумно оставлять один блок, так как не всегда читаем весь файл целиком. Поэтому оптимально размер блока делать 128 мб.

![image](https://github.com/user-attachments/assets/b8944f41-0654-4b0f-a608-0f02c4e4a6fd)

**Как делить на блоки?**

![image](https://github.com/user-attachments/assets/46040598-5ae7-4d98-af5e-17d3c1f9481b)

![image](https://github.com/user-attachments/assets/f95b95cf-8534-411e-9176-f95b536253e8)

Если файл меньше размера блока HDFS, то блок записывается размером как сам файл.

![image](https://github.com/user-attachments/assets/e56350f7-2464-45f9-bac4-6fb759ee87f3)

**Репликация**

Например, хотим загрузить файл размером 150 Мбайт.

Будем учитывать, что по умолчанию в нашей сборке HDFS стоит фактор репликации - 3,  а размер каждого блока 64 Мб.

1. Разделим наш файл 150 Мбайт на размер блока 64 Мб = получится 2.34375 файлов. Так как количество файлов не может быть неровным, то получится что 2 файла будут с одинаковыми размерами в 64 Мб, а третий файл будет остатком от деления, то есть 22 Мбайт.

2. Исходя из того, что файл был разделен на 3 части, очевидно, что необходимо иметь хотя бы 3 дата ноды. Таким образом 2 файла по 64 Мбайт будут загружены на НОДУ1 и НОДУ2, а на НОДУ3 положится файл размером 22 МБайт.

3. Не будем забывать о том, что HDFS - отказоустойчивая система, и, в случае выхода одной дата ноды, информация все равно должна быть доступна на другой ноде. То есть сейчас оперируем 3 нодами, 3 кусочками файла. То есть схема будет выглядеть следующим образом:

![image](https://github.com/user-attachments/assets/b8ec00f6-ecda-42ae-adec-0af485e23704)

В файловой системе в терминале это выглядит вот так:

![image](https://github.com/user-attachments/assets/871e4473-1c5a-4e32-8de8-3a120c6cec11)

**Архитектура Hadoop Distributed File System (HDFS)**

Архитектура Hadoop Distributed File System (HDFS) состоит из нескольких ключевых компонентов, которые работают вместе для обеспечения распределенного хранения и обработки данных. Вот основные компоненты и принципы архитектуры HDFS:

1. NameNode (узел имени):

NameNode является главным узлом метаданных в HDFS.

Он хранит информацию о том, где расположены блоки данных в файловой системе, и о состоянии файлов и каталогов.

NameNode также отслеживает работу DataNode и координирует операции записи, чтения и удаления файлов.

Вся метаинформация о файлах и блоках данных хранится в оперативной памяти NameNode и, поэтому, она должна быть достаточно емкой для обработки больших объемов данных.

2. DataNode (узел данных):

DataNode представляет собой узел хранения фактических блоков данных.

Он хранит блоки данных на локальных дисках и отвечает за чтение и запись данных по запросу NameNode и клиентов.

DataNode периодически отправляет отчеты о своем состоянии NameNode, сообщая ему о доступности блоков данных.

3. Secondary NameNode (вторичный узел имени):

Secondary NameNode предназначен для обслуживания NameNode и выполнения операций по резервному копированию и слиянию журналов транзакций.

Вторичный узел имени не является резервным узлом для NameNode. Он просто помогает восстановлению системы после сбоев и выполняет процедуры слияния и архивирования, чтобы уменьшить время восстановления в случае необходимости.

4. Client (клиент):
   
Клиенты представляют собой приложения, которые используют HDFS для чтения, записи и обработки данных.

Клиенты отправляют запросы на операции файловой системы (например, чтение файла) к NameNode и затем взаимодействуют с DataNode для фактического доступа к данным.

5. Block (блок):
   
Данные в HDFS разделены на блоки фиксированного размера (обычно 64 МБ по умолчанию).

Блоки данных реплицируются на разные узлы данных для обеспечения отказоустойчивости и достижения высокой доступности данных.

![image](https://github.com/user-attachments/assets/fbe87fd5-279f-4a2e-b8e8-cd7da6e61f89)

![image](https://github.com/user-attachments/assets/9c567b64-dea2-464f-98c2-483baf6019aa)

# Установка HDFS через Docker

**Склонировать проект:**

`git clone https://github.com/big-data-europe/docker-hive.git`

![image](https://github.com/user-attachments/assets/68d67b3e-174d-4693-af64-0cef1fbbab1c)

**Перейти в папку с проектом:**

`cd docker-hive`

![image](https://github.com/user-attachments/assets/ff6600cd-4d78-4bd7-a6b3-9156505b13aa)

**Запустить Docker образ:**

`docker-compose up -d`

После успешного запуска, получим сообщение:

![image](https://github.com/user-attachments/assets/5de27163-1df4-4d8e-9e03-2b804689e7e3)

Далее необходимо залезть в контейнер и поработать с hdfs.

Посмотрим список процессов командой `docker ps`:

![image](https://github.com/user-attachments/assets/1b790337-9029-4fe2-8264-12087cba8a60)

Далее ищем контейнер с названием docker-hive-namenode-1. Вводим следующую команду, чтобы туда провалиться:

`docker exec -it docker-hive-namenode-1 /bin/bash`

![image](https://github.com/user-attachments/assets/dea99366-f130-49ef-a1b5-a6769a1f8427)

![image](https://github.com/user-attachments/assets/dfe55daf-d23c-45a7-9fe3-1cb1968eaf8f)

Теперь мы в HDFS. Чтобы проверить это, вводим команду:

`hadoop version`

![image](https://github.com/user-attachments/assets/a4152183-b6c0-478e-bb95-2a043d0867b1)

Так же если ввести команду:

`hdfs dfsadmin -report`

Увидим:

![image](https://github.com/user-attachments/assets/086259dd-5a27-4f5e-a82c-6302f59b3c35)

Команда `hdfs dfsadmin -report` используется в Hadoop для получения сводной информации о состоянии кластера HDFS (Hadoop Distributed File System). Она позволяет администраторам системы видеть статистику и состояние файловой системы.






