## Оглавление

- [Как хранят и обрабатывают большие данные?](#как-хранят-и-обрабатывают-большие-данные)
- [Что такое ETL/ELT процессы?](#что-такое-etlelt-процессы)
- [batch и streaming](#batch-и-streaming)
- [Виды баз данных](#виды-баз-данных)
- [Что такое OLAP/OLTP?](#что-такое-olapoltp)
- [Что такое таблица и из каких элементов она состоит?](#что-такое-таблица-и-из-каких-элементов-она-состоит)
- [ACID](#ACID)
- [Ключи](#ключи)
- [Виды связей таблиц](#виды-связей-таблиц)
- [Нормализация](#нормализация)
- [DWH Data Warehouse](#DWH-Data-Warehouse)
- [Модели данных](#Модели-данных)
- [Озеро данных](#Озеро-данных)
- [Болото данных](#Болото-данных)
- [Batch-обработки и Lambda-архитектуры](#Batch-обработки-и-Lambda-архитектуры)
- [Подходы к проектированию DWH](#Подходы-к-проектированию-DWH)
- [SCD](#SCD)
- [NoSQL хранилища данных](#NoSQL-хранилища-данных)
  
## Как хранят и обрабатывают большие данные?

**Big data**

Большие данные нельзя хранить в традиционных хранилищах и нельзя обрабатывать стандартными инструментами.

Потому что хранение будет неоптимизированным, а взятие информации будет занимать очень много времени, что для бизнеса недопустимо. 

Именно поэтому начали создавать специальный софт для хранения, обработки, загрузки и выгрузки больших данных.

---------------------------------------

**1. Распределенные файловые системы:**

**Hadoop Distributed File System (HDFS):**

Это распределенная файловая система, которая является основой платформы Hadoop. HDFS позволяет хранить большие объемы данных, распределяя их по кластерам серверов. Данные разбиваются на блоки, которые хранятся на разных узлах кластера, обеспечивая отказоустойчивость и высокую доступность.

**Amazon S3 (Simple Storage Service):**

Облачное хранилище, используется для хранения больших данных. S3 предлагает высокую масштабируемость, надежность и доступность, что делает его популярным выбором для хранения неструктурированных и полуструктурированных данных.

**Google Cloud Storage, Microsoft Azure Blob Storage:**

Подобные сервисы облачного хранения от Google и Microsoft предлагают аналогичные возможности для хранения больших объемов данных в облаке с высокой доступностью и безопасностью.

---------------------------------------

**2. NoSQL базы данных:**

**Apache Cassandra:**

Распределенная NoSQL база данных, которая позволяет хранить и управлять большими объемами данных на нескольких серверах. Cassandra хорошо подходит для работы с большими данными благодаря своей масштабируемости и высокой доступности.

**MongoDB:**

Документно-ориентированная база данных, которая позволяет хранить данные в формате BSON (расширение JSON). MongoDB хорошо справляется с большими объемами данных и обеспечивает гибкость в работе с полуструктурированными и неструктурированными данными.

**HBase:**

NoSQL база данных, построенная поверх HDFS, которая обеспечивает быструю запись и чтение данных, что делает её подходящей для работы с большими данными в реальном времени.

---------------------------------------

**3. И в отдельную группу вынесены еще 2 способа хранения данных, поскольку они не раскатываются образом по типу скачал-установил. Их дополнительно нужно настраивать, при чем не быстро.**

**Data Lake:**

Data Lake — это централизованное хранилище, в котором можно хранить структурированные, полуструктурированные и неструктурированные данные в их исходном виде. 

Data Lake поддерживает хранение данных любого типа и позволяет организациям собирать и обрабатывать данные из множества источников.

**Хранилища данных (Data Warehouses):**

Эти хранилища данных позволяют эффективно хранить и обрабатывать структурированные данные, а также выполнять сложные аналитические запросы над большими объемами данных. 

**Обработка больших данных**

**1. Распределенные вычисления:**

**Apache Hadoop:**

Платформа для распределенной обработки больших данных, которая включает в себя HDFS и MapReduce. MapReduce позволяет разбивать задачи на небольшие подзадачи, которые выполняются параллельно на разных узлах кластера, а затем собираются в единый результат. 

**Apache Spark:**

Платформа для распределенных вычислений, которая обеспечивает более быструю обработку данных по сравнению с Hadoop благодаря использованию in-memory вычислений (и не только). Spark поддерживает разнообразные задачи: от обработки потоков данных (Streaming) до машинного обучения (MLlib).

---------------------------------------

**2. Потоковая обработка данных:**

**Apache Kafka:**

Платформа для обработки потоков данных в реальном времени, которая позволяет обрабатывать большие объемы данных, поступающих с высокой скоростью. Kafka используется для сбора, хранения и обработки потоков данных, таких как события IoT или логи сервера. Но на самом деле обработку именно самих данных кафка не делает. Она их перенаправляет.

**Apache Flink, Apache Storm:**

Инструменты для потоковой обработки данных, которые обеспечивают низкую задержку и возможность обработки данных в реальном времени. Flink и Storm используются для задач, требующих мгновенного отклика на поступающие данные. Они являются аналогами Kafka.

---------------------------------------

**3. Инструменты для анализа данных:**

**Hive:**

Инструмент, работающий поверх Hadoop, который позволяет выполнять SQL-подобные запросы к данным, хранящимся в HDFS. Hive упрощает анализ больших данных, предоставляя интерфейс, знакомый пользователям SQL.

**Presto:**

Движок для выполнения SQL-запросов по распределённым данным, который обеспечивает высокую производительность и возможность работы с данными, хранящимися в разных системах (HDFS, S3, реляционные базы данных).

---------------------------------------

**4. Облачные платформы для обработки больших данных:**

**Google Cloud BigQuery:**

Инструмент для обработки больших данных, который позволяет выполнять SQL-запросы по большим наборам данных, хранящимся в облаке. BigQuery обеспечивает высокую производительность и масштабируемость, позволяя обрабатывать петабайты данных за считанные секунды.

**Amazon EMR (Elastic MapReduce):**

Облачная платформа от Amazon для обработки больших данных, основанная на Apache Hadoop и Apache Spark. EMR позволяет быстро разворачивать кластеры и обрабатывать большие объемы данных в облаке.

**Microsoft Azure Synapse Analytics:**

## Что такое ETL/ELT процессы?

**ETL**

**Extract (Извлечение):**

Данные извлекаются из различных источников данных, таких как базы данных, файловые системы, приложения и другие системы.
Источниками могут быть структурированные и полуструктурированные данные, такие как реляционные базы данных, CSV-файлы, XML, JSON и другие.

**Transform (Преобразование):**

Извлеченные данные преобразуются в соответствии с требованиями целевой системы. Это очистка данных, фильтрация, агрегация, сортировка, объединение и другие операции.
На этом этапе данные могут быть преобразованы в более подходящий формат для анализа и хранения, например, нормализованы, денормализованы, агрегированы и т.д.

**Load (Загрузка):**

Преобразованные данные загружаются в целевую систему, такую как хранилище данных. После этого данные готовы для использования аналитическими инструментами и бизнес-приложениями.

**Преимущества ETL:**

Преобразование данных до загрузки позволяет гарантировать, что в хранилище данных попадают только качественные, очищенные и готовые к анализу данные.

Поскольку данные уже преобразованы до загрузки, они могут быть быстрее обработаны аналитическими запросами.

**Недостатки ETL:**

Преобразование данных до их загрузки может потребовать значительных вычислительных ресурсов на промежуточных серверах.

Весь процесс ETL может занимать значительное время, особенно если объемы данных велики.

----------------------------------------

**ELT**

ELT — это более современный подход, который стал популярным с развитием мощных систем обработки и хранения данных. Он также состоит из трёх этапов, но порядок операций отличается:

**Extract (Извлечение):**

Как и в ETL, данные извлекаются из различных источников данных.

**Load (Загрузка):**

Извлеченные данные загружаются в целевую систему, такой как озеро данных или хранилище данных, без предварительного преобразования. Это может быть особенно полезно для хранения больших объемов неструктурированных или полуструктурированных данных.

**Transform (Преобразование):**

Преобразование данных происходит уже после их загрузки в целевую систему. Эта операция выполняется непосредственно на мощностях хранилища данных или озера данных, используя доступные вычислительные ресурсы.

Данные могут быть трансформированы по мере необходимости, например, при выполнении аналитических запросов или в процессе подготовки отчетов.

**Преимущества ELT:**

Подход ELT особенно эффективен для работы с большими объемами данных, так как вычислительные мощности целевых систем могут быть масштабированы в зависимости от потребностей.

Данные загружаются в "сыром" виде, что позволяет выполнять разные преобразования в зависимости от задачи. Это упрощает добавление новых типов данных и их анализ без необходимости изменения всего процесса загрузки.

Поскольку данные загружаются без предварительного преобразования, процесс загрузки может быть быстрее, что особенно важно для больших данных.

**Недостатки ELT:**

Преобразование данных требует значительных вычислительных ресурсов от хранилища данных, что может увеличивать стоимость и нагрузку на систему.

Поскольку данные загружаются без предварительного преобразования, существует риск того, что в хранилище данных попадут некачественные или ошибочные данные, что может усложнить последующую работу с ними.

## batch и streaming. 

ETL/ELT это просто приоритетность выполнения операций в инструментах, то batch и streaming диктует, какие инструменты нужны в этой цепочке.

**Batch обработка данных**

Это метод обработки данных, при котором данные собираются, группируются в пакеты или блоки, а затем обрабатываются в рамках единого процесса. Пакетная обработка выполняется периодически, по расписанию или по мере накопления данных. Этот метод подходит для ситуаций, когда данные не требуют мгновенной обработки и могут быть обработаны с задержкой.

**Примеры пакетной обработки:**

Ежедневные отчеты: Обработка данных о продажах за день, которая запускается в конце дня.

Периодическая загрузка данных: Загрузка и обновление данных в хранилище данных раз в сутки или раз в неделю.

Анализ логов: Обработка и анализ логов серверов или приложений, которые собираются за определенный период.

**Характеристики пакетной обработки:**

Задержка: Данные обрабатываются с определенной задержкой, поскольку обработка начинается только после накопления определенного объема данных.

Высокая производительность: Пакетная обработка позволяет оптимизировать ресурсы и производительность, поскольку данные обрабатываются большими объемами, а не в реальном времени.

Масштабируемость: Подходит для обработки больших объемов данных, так как операции могут быть параллелизированы и распределены по кластерам серверов.

Примеры технологий: Apache Hadoop, Apache Spark (в режиме batch), ETL-процессы.

--------------------------------------------

**Streaming обработка данных**

Это метод обработки данных, при котором данные обрабатываются непрерывно по мере их поступления. В отличие от пакетной обработки, потоковая обработка позволяет обрабатывать данные практически в реальном времени, что особенно важно в случаях, когда нужна быстрая реакция на поступающие данные.

**Примеры потоковой обработки:**

Мониторинг финансовых транзакций: Обнаружение мошеннических операций в реальном времени.

**Характеристики потоковой обработки:**

Минимальная задержка: Данные обрабатываются с минимальной задержкой после их поступления в систему, что позволяет получать результаты практически в реальном времени.

Непрерывность: Обработка данных происходит непрерывно, без необходимости накопления данных в пакеты.

Масштабируемость и адаптивность: Потоковая обработка должна быть способна справляться с переменным объемом данных, поддерживая масштабируемость и адаптивность системы.

Примеры технологий: Apache Kafka, Apache Flink, Apache Storm, Apache Spark Streaming, Google Cloud Dataflow.

##  Виды баз данных

Внутриуровнево базы данных делятся на виды:

**Реляционные базы данных** организуют данные в виде таблиц, где каждая таблица состоит из строк (записей) и столбцов (полей). Таблицы могут быть связаны между собой через ключи.

**Нереляционные NoSQL(NotOnlySQL) базы данных** предназначены для работы с данными, которые не вписываются в традиционные реляционные модели. 
Они могут хранить данные в виде документов (обычно JSON), ключ-значение пар, графов или столбцов. NoSQL базы данных часто используются для работы с большими объемами данных и в высоконагруженных системах.

**Колоночные базы данных** — это базы данных, в которых данные организуются и хранятся по столбцам, а не по строкам, как в традиционных реляционных базах данных. 
Этот подход обеспечивает высокую эффективность при выполнении аналитических запросов, особенно на больших объемах данных. Пример *ClickHouse*

![image](https://github.com/user-attachments/assets/e2c2c067-cf90-478f-a1fd-e5ab55352a1f)

**Так же есть другие виды баз данных:** Иерархические, Документоориентированные, Графовые, Объектно-ориентированные

## Что такое OLAP/OLTP?

Верхнеуровнево базы данных делятся на OLTP и OLAP.

**OLTP (Online Transaction Processing)** — это тип системы обработки данных, предназначенный для управления транзакциями в режиме реального времени. Эти системы обрабатывают большое количество коротких онлайн-транзакций (например, покупка товаров, внесение платежей, обновление записей и т.д.). OLTP-системы оптимизированы для быстрого выполнения большого количества запросов, таких как вставка, обновление и удаление данных.

**Транзакции** в контексте баз данных — это набор операций, выполняемых как единое целое. 

Транзакция гарантирует, что все операции в её составе будут выполнены полностью и корректно или не будут выполнены вовсе. 

Транзакции обеспечивают целостность данных и помогают избежать ситуаций, когда данные остаются в непоследовательном состоянии из-за сбоев или ошибок. 

**Основные характеристики OLTP:**

OLTP-системы поддерживают большое количество одновременных пользователей и операций.

Данные часто структурированы и нормализованы для уменьшения избыточности и обеспечения целостности данных.

OLTP-системы обеспечивают ACID-свойства (атомарность, согласованность, изолированность, долговечность), что важно для обеспечения точности и надежности транзакций.
Банковские системы, системы управления заказами, системы бронирования билетов, системы управления складом.

Пример: Интернет-магазин, который обрабатывает заказы клиентов в реальном времени, добавляет записи о заказах, обновляет информацию о запасах и обрабатывает платежи.

------------------------------------

**OLAP (Online Analytical Processing)** — это тип системы обработки данных, предназначенный для анализа больших объемов данных. OLAP-системы используются для поддержки сложных аналитических запросов, таких как анализ трендов, многомерный анализ данных, генерация отчетов и бизнес-аналитика. В отличие от OLTP, OLAP-системы оптимизированы для чтения данных и выполнения сложных запросов.

**Основные характеристики OLAP:**

OLAP-системы позволяют пользователям анализировать данные по различным измерениям (например, по времени, географии, продукту и т.д.).

Данные часто хранятся в денормализованном виде для ускорения выполнения сложных запросов.

OLAP-системы предназначены для выполнения сложных аналитических операций.

Пример: Руководитель компании использует OLAP-систему для анализа продаж по регионам за последние пять лет, чтобы выявить тенденции и принять стратегические решения.

Подводя итоги, можно сказать, что OLTP подходит для постоянной вставки данных, но на выборку будет работать долго. OLAP, наоборот, вставляет данные медленно, а считывает их моментально.

## Что такое таблица и из каких элементов она состоит?

Основная единица данных в базах данных - это таблица. И все запросы пишутся чаще всего к таблицам, а не к базам данных :)

Таблица в контексте баз данных — это основная структура, используемая для хранения данных. 

Таблица организована в виде строк и столбцов, где каждая строка представляет собой запись **(или экземпляр данных)**, а каждый столбец представляет собой поле **(или атрибут)** с определенным типом данных.

**Атрибуты - название столбца.**

**Строки (кортежи): Строки представляют собой записи в таблице, каждая из которых содержит значения для всех столбцов. В каждой строке хранится информация о конкретном объекте или событии.**

## ACID

**Транзакции** в контексте баз данных — это набор операций, выполняемых как единое целое. 

Транзакция гарантирует, что все операции в её составе будут выполнены полностью и корректно или не будут выполнены вовсе. 

Транзакции обеспечивают целостность данных и помогают избежать ситуаций, когда данные остаются в непоследовательном состоянии из-за сбоев или ошибок.

![image](https://github.com/user-attachments/assets/14ad37ec-b8b2-49c6-96d5-5cc02bb1fb06)

---------------------------------------------------------

Представим себе ситуацию, когда переводите деньги с одного банковского счета на другой. Эта операция может быть представлена как транзакция, состоящая из следующих шагов:

- Уменьшение суммы на одном счете.

 - Увеличение суммы на другом счете.

Если один из этих шагов не удастся (например, из-за технической ошибки), вся транзакция должна быть отменена, чтобы не произошло некорректное изменение баланса на счетах. 

---------------------------------------------------------

**Что делать, если база данных не поддерживает транзакции?**

Если у БД нет транзакций, то мы ее и выбирать не будем, но это не так. Транзакции не являются чем-то важным и супер необходимым.

Если транзакции "из коробки" не доступны, можно либо:

- отслеживать состояние базы данных вручную

- использовать сторонние инструменты для управления транзакциями (например Kafka)

---------------------------------------------------------

**Какие БД поддерживают транзакции?**

MySQL: Поддержка транзакций доступна в таблицах, использующих механизм хранения InnoDB.

PostgreSQL: Полная поддержка транзакций, включая сложные транзакции и вложенные транзакции.

MongoDB: Поддержка транзакций на уровне нескольких документов начиная с версии 4.0. 

И многие другие.

Транзакция - это вставка данных в таблицу, которая всегда должна закончиться либо успехом, либо неудачей, но без изменения данных в БД.

---------------------------------------------------------

**Какие еще свойства должна соблюдать транзакция?**

**ACID** — это акроним, описывающий четыре ключевых свойства транзакций в системах управления базами данных (СУБД). 

Эти свойства обеспечивают надёжность транзакций и целостность данных в базе данных, даже в случае сбоев, ошибок или других непредвиденных ситуаций. 

Вот они слева направо - Атомарность (Atomicity), Согласованность (Consistency), Изолированность (Isolation), Долговечность (Durability).

**1. Атомарность (Atomicity)**

Атомарность гарантирует, что все операции в транзакции будут выполнены полностью или не будут выполнены вовсе. 

Если какая-либо часть транзакции не удается, все изменения отменяются, и база данных возвращается в исходное состояние.

Отправляете деньги с одного банковского счёта на другой. Транзакция включает два шага:

Списать деньги с одного счёта.

Зачислить деньги на другой счёт.

Если первый шаг выполнен успешно, но второй шаг не удался из-за сбоя, деньги не должны исчезнуть. 

Атомарность гарантирует, что либо оба шага будут выполнены (деньги будут переведены), либо ни один из них (деньги останутся на исходном счёте).

Зачем это нужно? Атомарность защищает от частично выполненных транзакций, которые могут привести к некорректному состоянию данных.

**2. Согласованность (Consistency)**

Согласованность гарантирует, что после завершения транзакции база данных остаётся в согласованном состоянии. Это значит, что все правила, ограничения и целостность данных будут соблюдены.

Допустим, у есть правило в базе данных, что сумма всех денег на счетах не может изменяться. Если вы переводите деньги с одного счёта на другой, общая сумма должна остаться неизменной.

Согласованность гарантирует, что транзакция не нарушит это правило: сумма на одном счёте уменьшится, а на другом увеличится ровно на ту же сумму.

Зачем это нужно? Согласованность обеспечивает, что транзакции не приведут к нарушению целостности и правил базы данных, что важно для корректного функционирования системы.

**3. Изолированность (Isolation)**

Изолированность гарантирует, что параллельно выполняемые транзакции не будут влиять друг на друга. Каждая транзакция выполняется так, как будто она единственная в системе.

Два человека одновременно пытаются купить последний билет на концерт. Без изолированности могло бы произойти, что оба видят доступный билет, оба пытаются его купить, и система продаст один билет дважды.

Изолированность гарантирует, что одна из транзакций будет завершена первой (человек успешно купит билет), а вторая транзакция либо увидит, что билетов больше нет, либо будет обработана позже.

Зачем это нужно? Изолированность предотвращает конфликты и ошибки, которые могут возникнуть при параллельной работе с одними и теми же данными.

**4. Долговечность (Durability)**

Долговечность гарантирует, что после успешного завершения транзакции её результаты сохранятся в базе данных и не будут потеряны, даже в случае сбоя системы.

После успешной оплаты (транзакция завершена) ваша покупка зафиксирована, и подтверждение получено.

То есть, после завершения оплаты, система зафиксирует вашу покупку, и вы получите подтверждение об успешной транзакции.

Зачем это нужно? Долговечность обеспечивает сохранение результатов транзакции, что особенно важно для критически важных операций, таких как банковские переводы или покупки.

**Пример**

Так ли важны эти свойства для транзакций? Неужели никаким из них нельзя пренебречь? Ответ будет очень простой - представьте себя покупателем. И тут куча ситуаций, которые могут возникнуть, а самое главное, что у каждого из этих случаев будут последствия.

Вы видите, что ноутбук есть в наличии, и решаете его купить. Однако, поскольку не используется транзакция, другая покупка может одновременно снизить запасы на складе до нуля.

Деньги с вашего счёта успешно списываются, но между этим и обновлением запасов на складе происходит сбой.

Произошел сбой на сервере, и информация о том, что ноутбук был продан, не была обновлена на складе. В результате запас ноутбуков на складе остаётся прежним, хотя фактически ноутбук уже не доступен.

Последствия -  

Вы потеряли деньги, но заказ не был оформлен. В системе нет следов вашей покупки, и вы не получите ноутбук, хотя заплатили за него.

На сайте может отображаться, что ноутбук всё ещё доступен для покупки, хотя его уже нет на складе. Это может привести к множеству разочарованных клиентов, которые будут пытаться купить недоступный товар.

Без следов транзакции в системе может быть сложно доказать, что вы совершили покупку, и вернуть свои деньги.

## Ключи

**Ключи в реляционных базах данных** — это особые столбцы или комбинации столбцов в таблицах, которые служат для идентификации записей и определения связей между таблицами. 

Ключи играют важную роль в обеспечении целостности данных и организации отношений между таблицами в базе данных.

**2 ключевых момента:** 

- Ключи нужны для идентификации каждой строки в таблице. То есть, чтобы у каждой строки было свое уникальное значение. Например, у человека это серия и номер паспорта, у машин VIN номер.

- Ключи нужны для образования отношений между таблицами.

-------------------------------------------------------------

**Первичный ключ (Primary Key).**

Таблица 1: Employees (Сотрудники)

![image](https://github.com/user-attachments/assets/0b8d920a-8c4d-439c-9575-ccc7d58f7c37)

Таблица 2: Departments (Отделы)

![image](https://github.com/user-attachments/assets/8dbc4f63-3f03-4895-8b01-658c0b64600a)

*Таблица: Employees*

Описание: В таблице Employees столбец EmpID является первичным ключом, потому что он уникально идентифицирует каждого сотрудника. Значения в этом столбце уникальны и не могут быть пустыми.

Пример: EmpID = 1 относится к сотруднику по имени Alice.

*Таблица: Departments*

Описание: В таблице Departments столбец DeptID является первичным ключом, потому что он уникально идентифицирует каждый отдел.

Пример: DeptID = 2 относится к отделу Engineering.

**Внешний ключ (Foreign Key).**

Таблица: Employees

Описание: В таблице Employees столбец DeptID является внешним ключом, который ссылается на столбец DeptID в таблице Departments. Это означает, что каждый сотрудник связан с отделом через этот внешний ключ.

Пример: У сотрудника с EmpID = 1 (Alice) DeptID = 1, что в свою очередь является ссылкой на отдел HR в таблице Departments.

**Составной ключ (Composite Key)**

Ситуация: Допустим, у нас есть таблица EmployeeProjects (которая описывает проекты сотрудников), которая отслеживает, какие сотрудники работают над какими проектами. Для уникальной идентификации записи необходимо использовать комбинацию двух столбцов: EmpID и ProjectID.

*Таблица: EmployeeProjects*

![image](https://github.com/user-attachments/assets/b3546b7d-b438-4289-9391-60a3049ca9b9)

В этой таблице комбинация EmpID и ProjectID служит составным первичным ключом, что значит, что для каждого проекта сотрудник может быть указан только один раз. Уникально идентифицирует сочетание сотрудника и проекта, на котором он работает. Ни один отдельный столбец (EmpID или ProjectID) не может быть уникальным, но их комбинация является уникальной.

![image](https://github.com/user-attachments/assets/a4f93468-94f1-4220-87f3-da03c4a573e9)

## Виды связей таблиц

**Связь "Один к одному" (One-to-One)** - Это когда одна запись в таблице A соответствует одной записи в таблице B. (Пример пользователи и профили).

**Связь "Один ко многим" (One-to-Many)** - Это когда одна запись в таблице A может соответствовать нескольким записям в таблице B.

Рассмотрим две таблицы: Клиенты и Заказы. В этой связи один клиент может сделать несколько заказов, но каждый заказ принадлежит только одному клиенту.

**Связь "Многие ко многим" (Many-to-Many)** - Это когда одна запись в таблице A может соответствовать многим записям в таблице B, и наоборот.

Рассмотрим три таблицы: Студенты, Курсы и промежуточную таблицу Регистрации. В этой связи один студент может записаться на несколько курсов, и один курс может включать нескольких студентов.

## Нормализация

**Нормализация** — это процесс организации данных в базе данных таким образом, чтобы минимизировать избыточность (дублирование) и избежать аномалий при вставке, обновлении или удалении данных. Идея заключается в том, чтобы разложить данные на логически связанные таблицы, каждая из которых отвечает за хранение определенного набора информации.

**Зачем нужна нормализация?**

Когда одна и та же информация хранится в нескольких местах, это может привести к ошибкам и неконсистентности данных. Нормализация помогает хранить каждую единицу информации только один раз.

Если данные хранятся правильно и связаны логически, то уменьшается вероятность ошибок при их обновлении.

Правильно организованная база данных легче модифицируется и обновляется без риска нарушить работу всей системы.

**А что такое нормальные формы?** 

**Нормальные формы**-это шаги нормализации, которые следуют друг за другом. Каждая следующая нормальная форма строится на основе предыдущей и требует выполнения определенных правил.
 
 ----------------------------------------
 
**Первая нормальная форма (1NF)**

Суть:

Данные в таблице должны быть атомарными, то есть каждая ячейка таблицы должна содержать только одно значение.
В таблице не должно быть повторяющихся строк.
Возьмем таблицу Заказы.

![image](https://github.com/user-attachments/assets/91e4967d-db02-486f-ba7c-0e5b0ac90e03)

Здесь, в колонке Products содержится несколько значений в одной ячейке, что нарушает 1NF. 

![image](https://github.com/user-attachments/assets/172e1997-e37f-4f6b-a102-c0f615544276)

Теперь каждая ячейка содержит только одно значение.

 ----------------------------------------

**Вторая нормальная форма (2NF)**

Суть:

Таблица должна соответствовать 1NF.
Все неключевые атрибуты должны зависеть от всего первичного ключа, а не от его части (если ключ составной).
Представим таблицу Продажи:

![image](https://github.com/user-attachments/assets/d3db6fad-1a99-4fb3-acd4-bc1e9ee39cdb)

Здесь CustomerName зависит только от OrderID, а не от составного ключа (OrderID, ProductID). Это нарушение 2NF.

Приведем к 2NF, разделим таблицу на две: 

Таблица Заказы

![image](https://github.com/user-attachments/assets/9d11eae6-8632-4472-821e-7ec972f7426b)

Таблица Продажи:

![image](https://github.com/user-attachments/assets/a5e9f494-0d28-459e-a9eb-08083a186d64)

Теперь CustomerName зависит только от OrderID, а продукты связаны с заказами через другую таблицу. 

 ----------------------------------------

**Третья нормальная форма (3NF)**

Суть:

Таблица должна соответствовать 2NF.
Не должно быть транзитивных зависимостей, то есть неключевые атрибуты не должны зависеть друг от друга.
Таблица Сотрудники:

![image](https://github.com/user-attachments/assets/a260fd1b-359a-4f71-9a09-d8803bd0f1d1)

Здесь DepartmentName зависит от DepartmentID, а DepartmentID — от EmployeeID. Это транзитивная зависимость.

Приведение к 3NF:

Разделяем таблицу на две:

Таблица Сотрудники:

![image](https://github.com/user-attachments/assets/980ccadb-eb4d-4222-855d-adda574753d6)

Таблица Отделы: 

![image](https://github.com/user-attachments/assets/12aad3a4-95d3-4680-ac64-91881dc85883)

Теперь каждая таблица содержит данные, зависящие только от своего первичного ключа. 

Почему не всегда используют нормализацию?

Иногда, для улучшения производительности, базы данных сознательно не нормализуют полностью. Это называется денормализацией. Она позволяет ускорить выполнение запросов, уменьшая количество необходимых соединений (join) таблиц. Однако, это может привести к дублированию данных и сложности в поддержании их целостности.

## DWH (Data Warehouse)

**DWH (Data Warehouse)** - это централизованное хранилище данных, предназначенное для хранения и анализа больших объемов **структурирванных** данных из различных источников. 

**DWH (Data Warehouse)** обычно включают в себя следующие основные компоненты:

1. ETL (Extract, Transform, Load): ETL является ключевым компонентом DWH и отвечает за извлечение данных из различных источников, их трансформацию и загрузку в хранилище данных. ETL процесс обеспечивает очистку, преобразование и интеграцию данных, чтобы они соответствовали требованиям DWH.

2. Хранилище данных: Хранилище данных представляет собой централизованное место для хранения и управления данными в DWH. Обычно используется реляционная база данных, специально оптимизированная для аналитических операций и запросов.

3. Моделирование данных: Моделирование данных включает определение структуры данных в DWH, таких как схемы звезды или снежинки. Моделирование данных облегчает аналитический процесс и обеспечивает эффективность выполнения запросов.

4. Аналитический инструментарий: Аналитический инструментарий включает набор инструментов и технологий для анализа данных в DWH. Это может включать OLAP (Online Analytical Processing) инструменты, инструменты визуализации данных, инструменты машинного обучения и другие.

5. Метаданные: Метаданные представляют собой описание и характеристики данных в DWH. Они содержат информацию о структуре данных, источниках, связях между таблицами и другие метаданные, необходимые для понимания и использования данных в DWH.

6. Инструменты администрирования: Инструменты администрирования обеспечивают управление и мониторинг DWH, включая задачи управления пользователями, безопасностью, мониторинг производительности, резервное копирование и восстановление данных и другие административные функции.

![photo_2025-07-30_15-59-17](https://github.com/user-attachments/assets/6fd79836-ebc3-43eb-bfce-15c63c1efb85)

<img width="1498" height="712" alt="image" src="https://github.com/user-attachments/assets/6737d1b6-2e57-47ac-a974-dd7f4d0eee8f" />

<img width="1115" height="379" alt="image" src="https://github.com/user-attachments/assets/80694ab9-915b-4c8e-a97a-9177f70fbe75" />

<img width="1381" height="583" alt="image" src="https://github.com/user-attachments/assets/9fc80daf-d69e-4a8c-87e9-dfe7ebced433" />

**Архитектура DWH**

<img width="1380" height="476" alt="image" src="https://github.com/user-attachments/assets/188cbbba-5d04-45f3-9ce6-5b2c6ea7ec41" />

**Первичный слой данных**

Операционный слой первичных данных (Primary Data Layer, raw или staging) – это уровень, на котором выполняется загрузка информации из систем-источников в исходном качестве с сохранением полной истории изменений. На этом слое происходит абстрагирование следующих слоев хранилища от физического устройства источников данных, способов их сбора и методов выделения изменений.

**Центральный слой данных**

Ядро хранилища (Core Data Layer) – центральный слой, в котором происходит консолидация данных из разных источников, приводя их к единым структурам и ключам. Здесь осуществляется основная работа с качеством данных и трансформациями, чтобы абстрагировать потребителей от особенностей логического устройства источников данных и необходимости их взаимного сопоставления.

**Слой витрин данных**

Слой аналитических витрин (Data Mart Layer) – уровень, где данные преобразуются в структуры, удобные для анализа и использования в BI-дэшбордах или других системах-потребителях. Витрина данных (Data Mart) представляет собой срез хранилища данных в виде массива тематической, узконаправленной информации, ориентированной, например, на пользователей одной рабочей группы или департамента.

## Модели данных

**Таблица фактов** — главная таблица, в которой пишутся события, например, текущие заказы или действия пользователей на сайте. Т.е. некие события, которые скорее всего имеют уникальный характер.

**Таблица измерений (англ. dimension table)** — таблица, в которой хранятся описания объектов. Например id, ФИО курьера, который доставил заказ. Или данные каждого клиента. Таблицы измерений удобны тем, что там можно хранить те данные, которые не часто меняются. Очевидно, что писать в таблице фактов номер телефона клиента будет избыточно. Нам достаточно один раз его записать в таблицу измерений и дать ссылку на это в таблице фактов. И при любом запросе к определенному заказу, мы всегда получим актуальный номер телефона клиента, потому что мы изменили его в таблице измерений.

**«Звезда»** - имеет централизованное хранилище данных, которое хранится в таблице фактов. Схема разбивает таблицу фактов на ряд денормализованных таблиц измерений. Таблица фактов FACT содержит данные, которые будут использоваться для составления отчетов, а таблица измерений DIM (от англ. Dimension - измерение) описывает хранимые данные.

<img width="450" height="409" alt="image" src="https://github.com/user-attachments/assets/97306fed-6955-4596-9da8-de4b4bdcc4cb" />

В нашем примере центральная таблица (фактическая таблица) как раз и содержит в себе значения фактов (поставка заказа), а 4 таблицы вокруг (измерительные таблицы) - содержат в себе измерения (dimension): поставщика(supplier), сотрудника(employee), времени (time) и товара (product).  Обратите внимание, что таблица фактов содержит в основном только идентификаторы - ссылки на измерительные таблицы.

**«Снежинка»** - отличается тем, что использует нормализованные данные. Нормализация означает эффективную организацию данных так, чтобы все зависимости данных были определены, и каждая таблица содержала минимум избыточности. Таким образом, отдельные таблицы измерений разветвляются на отдельные дополнительные таблицы измерений.

<img width="450" height="442" alt="image" src="https://github.com/user-attachments/assets/225a3dfa-8d07-4e9e-834d-c1c8eb3e1a1f" />

Схема «снежинки» использует меньше дискового пространства и лучше сохраняет целостность данных. Основным недостатком является сложность запросов, необходимых для доступа к данным — каждый запрос должен пройти несколько соединений таблиц, чтобы получить соответствующие данные.Ну просто представьте сколько JOINов надо выполнить для получения "человекочитаемой" строки.

В этом примере фактическая таблица - это продажи `(Sales)`. Все остальные таблицы - измерительные.

Таблица `Sales` соединяет все измерительные таблицы через внешние ключи `(FK)`:

```
id_product с Product.
id_client с Client.
id_shop с Shop.
id_date с Time.
```

Таблицы измерений нормализованы:

```
Product соединена с Product Type и Brand.
Client соединена с Client Group.
Shop соединена с City, а City с Region.
Brand соединена с Supplier.
Time соединена с Month, а Month с Quarter.
```

**Data Vault** - это методология проектирования хранилищ данных, которая обеспечивает гибкость, масштабируемость и отслеживаемость изменений в данных.

**Основные принципы Data Vault включают:**

1) Модульность: Хранилище данных строится из набора модулей (hubs, links, satellites), каждый из которых отвечает за определенный аспект данных и может быть легко модифицирован или расширен без влияния на другие части хранилища.

2) Историчность: Data Vault сохраняет всю историю изменений данных, что позволяет аналитикам проводить анализ изменений во времени и понимать эволюцию данных.

3) Гибкость: Модель Data Vault легко адаптируется к изменениям в структуре и источниках данных, что делает ее более гибкой и устойчивой к изменениям в бизнес-требованиях.

4) Отслеживаемость: Data Vault обеспечивает четкое отслеживание источников данных и связей между ними, что облегчает понимание происхождения и структуры данных.

Data Vault состоит из трех основных элементов: хабов `(hubs)`, связей `(links)` и спутников `(satellites)`.

<img width="843" height="306" alt="image" src="https://github.com/user-attachments/assets/f39e900e-9e18-4b0c-b9b2-531b61930c25" />

- `Хабы (Hubs)`: Хабы представляют собой уникальные списки ключей для каждой сущности данных. Они являются центральными элементами модели и служат для централизованного хранения ключевых атрибутов сущности.

- `Связи (Links)`: Связи представляют собой ассоциативные таблицы, которые устанавливают связь между хабами. Они позволяют моделировать связи между различными сущностями данных.

- `Спутники (Satellites)`: Спутники содержат атрибуты, которые описывают контекст или детали данных из хабов или связей. Они могут содержать дополнительные атрибуты сущности, исторические данные или метаданные.

---------------------------------
*Пример*

Рассмотрим пример интернет-магазина, который хочет создать хранилище данных для анализа поведения клиентов. В названиях таблиц для наглядности укажем их принадлежность.

Еще раз уточним насчет содержания: хабы содержат ключевые бизнес-сущности, связи объединяют их, а сателлиты добавляют описательные и исторические данные. Этот подход обеспечивает гибкость, масштабируемость и возможность отслеживания изменений во времени.

Посмотрим на схему получившегося Data Vault:

<img width="868" height="596" alt="image" src="https://github.com/user-attachments/assets/156a196b-690b-495e-8eca-daedc6a6a1c3" />

*Хабы:*

Хабы содержат бизнес-ключи и являются основными таблицами для идентификации сущностей. Например, order_hub идентифицирует заказы, product_hub идентифицирует продукты, а customer_hub идентифицирует клиентов.

*Линки:*

Линки соединяют хабы между собой и представляют отношения между ними. Например, order_product_link соединяет заказы и продукты, а customer_order_link соединяет клиентов и заказы.

*Сателлиты:*

Сателлиты содержат описательные атрибуты и дополнительную информацию, связанную с хабами и линками. Например, order_satellite содержит данные о датах и статусах заказов, product_satellite содержит информацию о продуктах, а customer_satellite содержит информацию о клиентах.
 

Подведем небольшие итоги:  В очередной раз нельзя однозначно ответить на вопрос какая модель лучше. Выбор зависит от конкретных требований и контекста (опять всплывает основная сложность в работе DE - выбор оптимального инструмента):

-Если нужна простота и высокая производительность для отчетов и анализа, выбирайте модель "Звезда".

-Если требуется баланс между нормализацией и производительностью, рассмотрите модель "Снежинка".

-Если важна гибкость, масштабируемость и управление историчностью данных, Data Vault будет лучшим выбором.

## Озеро данных

Озеро данных (Data Lake) – это хранилище большого объема **структурированных, полуструктурированных и неструктурированных** данных, собранных или генерированных одной компанией. В таком подходе в озеро данных поступают все данные, которые собирает компания, без предварительной очистки и подготовки.

Примеры данных:

-Видеозаписи с беспилотников и камер наружного наблюдения.

-Транспортная телеметрия.

-Фотографии.

-Логи пользовательского поведения.

-Метрики сайтов.

-Показатели нагрузки информационных систем и пр.

Эти данные пока непригодны для типового использования в ежедневной аналитике в рамках BI-систем, но могут быть использованы для быстрой отработки новых бизнес-гипотез с помощью ML-алгоритмов.

<img width="1684" height="1190" alt="image" src="https://github.com/user-attachments/assets/00e437ff-9298-469a-b553-c85d6e74ab98" />

<img width="1156" height="540" alt="image" src="https://github.com/user-attachments/assets/e55b1183-1dea-4a86-a1b6-2b3b7328d115" />

<img width="1410" height="600" alt="lakehouse" src="https://github.com/user-attachments/assets/77c74100-d804-445e-ada6-9677bd02e0f8" />

**Основные особенности использования подхода:**

- Хранятся все данные, включая «бесполезные», которые могут пригодиться в будущем или не понадобиться никогда.

- Структурированные, полуструктурированные и неструктурированные разнородные данные различных форматов: от мультимедийных файлов до текстовых и бинарных из разных источников.

- Высокая гибкость, позволяющая добавлять новые типы и структуры данных в процессе эксплуатации.

- Из-за отсутствия четкой структуры необходима дополнительная обработка данных для их практического использования.

- Озеро данных дешевле DWH с точки зрения проектирования.

**Преимущества озера данных:**

- Масштабируемость: распределенная файловая система позволяет подключать новые машины или узлы без изменения структуры хранилища.

- Экономичность: Data Lake можно построить на базе свободного ПО Apache Hadoop, без дорогих лицензий и серверов.

- Универсальность: большие объемы разнородных данных могут использоваться для различных исследовательских задач (например, прогнозирование спроса или выявление пользовательских предпочтений).

- Быстрота запуска: накопленные объемы Data Lake позволяют быстро проверять новые модели, не тратя время на сбор информации из различных источников.

Ниже можно увидеть архитектуру Data LakeHouse. Она сочетает в себе Data Lake и DWH идеи
<img width="1388" height="674" alt="image" src="https://github.com/user-attachments/assets/c297fd47-7841-40de-bcff-6751ae7ac637" />

**Сравнение озера данных с обычными базами данных**

**Хранение данных:**

- Обычные базы данных: Хранят данные в структурированном формате, обычно в виде таблиц с определенными схемами и типами данных.

- Озеро данных: Хранит данные в неструктурированном или полуструктурированном формате, без необходимости предварительной обработки или установки схем.

**Типы данных:**

- Обычные базы данных: Преимущественно используются для хранения структурированных данных, таких как данные транзакционных систем.

- Озеро данных: Может хранить разнообразные типы данных, включая структурированные, неструктурированные и полуструктурированные данные.

**Цель использования:**

- Обычные базы данных: Применяются для операционных задач, таких как хранение, обновление и запросы структурированных данных в реальном времени.

- Озеро данных: Используется для аналитических целей, исследований данных, машинного обучения и хранения больших объемов данных из различных источников.

**Обработка данных:**

- Обычные базы данных: Предназначены для обработки данных в реальном времени с использованием SQL-запросов и транзакционных операций.

- Озеро данных: Предоставляет гибкость для обработки данных как в реальном времени, так и в пакетном режиме, с использованием различных инструментов и технологий.

**Скорость доступа:**

- Обычные базы данных: Обеспечивают быстрый доступ к структурированным данным с использованием индексов и оптимизации запросов.

- Озеро данных: Обеспечивает гибкий доступ к данным, но скорость доступа может быть медленнее из-за неструктурированности данных и необходимости их предварительной обработки перед анализом.

**Управление данными:**

- Обычные базы данных: Обычно имеют жесткую структуру с определенными правилами целостности и схемами данных, что облегчает управление данными.

- Озеро данных: Предоставляет большую гибкость, но требует более сложного управления данными из-за разнообразия форматов и источников данных.

# Сравнение Data Warehouse и Data Lake

| Критерий | Data Warehouse (DWH) | Data Lake (DL) |
|----------|---------------------|----------------|
| **Тип данных** | Только структурированные | Любые форматы (структурированные, полуструктурированные, неструктурированные) |
| **Схема данных** | Определяется до загрузки (Schema-on-Write) | Определяется при анализе (Schema-on-Read) |
| **Стоимость** | Дороже (из-за предварительной обработки) | Дешевле |
| **Основное использование** | Отчетность, BI-аналитика | Машинное обучение, эксперименты, исследовательский анализ |
| **Основная аудитория** | Бизнес-аналитики | Data Scientists, инженеры данных |
| **Гибкость** | Низкая (жесткая структура) | Высокая (гибкая архитектура) |
| **Время реализации** | Длительное | Быстрое развертывание |
| **Качество данных** | Высокое (очищенные данные) | Различное (сырые данные) |
| **Масштабируемость** | Вертикальная | Горизонтальная |

## Болото данных

**Болото данных** — это термин, используемый для описания озера данных, которое вышло из-под контроля. В болотах данных хранится множество данных, которые становятся неуправляемыми, неорганизованными и трудно доступными. Это может привести к низкому качеству данных и невозможности их эффективного использования.

## Batch-обработки и Lambda-архитектуры

На всех графиках мы используем стрелочки для описания перехода данных. Каждая отдельная стрелочка - это ETL процесс. 

**ETL** - это процесс преобразования данных, который состоит из:

- **Извлечение данных (Extraction - E)** - из одного или нескольких источников и подготовка их к преобразованию (загрузка в промежуточную область, проверка данных на соответствие спецификациям и возможность последующей загрузки в ХД);

- **Трансформация данных (Transform - T)** - преобразование форматов и кодировки, агрегация и очистка;

- **Загрузка данных (Load - L)** - запись преобразованных данных, включая информацию о структуре их представления (метаданные), в необходимую систему хранения (КХД) или витрину данных.

Существует также ELT подход. ETL и ELT — два разных способа загрузки данных в хранилище.

**ETL (Extract, Transform, Load)**

ETL сначала извлекают данные из пула источников данных. Данные хранятся во временной промежуточной базе данных. Затем выполняются операции преобразования, чтобы структурировать и преобразовать данные в подходящую форму для целевой системы хранилища данных. После этого структурированные данные загружаются в хранилище и готовы к анализу.

**ELT (Extract, Load, Transform)**

В случае ELT данные сразу же загружаются после извлечения из исходных пулов данных. Промежуточная база данных отсутствует, что означает, что данные немедленно загружаются в единый централизованный репозиторий. Данные преобразуются в системе хранилища данных для использования с инструментами бизнес-аналитики и аналитики.

-----------------------------------------------

# **Пакетная обработка**

ETL процесс может быть разным в зависимости от типа данных, которые в него передаются. В пакетной обработке данных существует разбиение данных по каким-либо диапазонам, обычно по временным диапазонам. В таком подходе данные обычно доставляются с задержкой. Для пакетной обработки характерны простая (относительная) разработка и тестирование, а также высокая эффективность для OLAP-систем и высокая пиковая нагрузка на железо.

**Пакетная обработка** - классический подход в построении DWH. Обычно хранилище данных строится за t−1, то есть данные в хранилище актуальны за вчерашний день. Пакетная обработка может быть и за последний час, и за предыдущие полчаса; это зависит от частоты жизни хранилища данных.

<img width="1274" height="227" alt="image" src="https://github.com/user-attachments/assets/dffa4770-ce2c-4922-984d-3f5e9a568011" />

# **Потоковая обработка**

**Потоковая обработка** - сервис обрабатывает и загружает весь поток информации, результат получается в режиме реального времени. Потоковая обработка сложнее в разработке и тестировании (относительно) чем пакетная. Для нее характерны низкая эффективность для OLAP-систем и равномерная нагрузка на железо.

<img width="1203" height="236" alt="image" src="https://github.com/user-attachments/assets/a4fc97da-b07c-444a-99c7-ef8164b88e7c" />

# **Lambda-архитектура**

Если мы объединим потоковую и пакетную обработку, то получим Lambda-архитектуру. У Lambda-архитектуры очень простой подход: мы делим общий поток данных на два потока. Первый поток — это пакетная обработка (Batch layer), а второй поток — это потоковая обработка (Real-time layer).

В **Batch layer** представлены Primary data layer и Core layer из классического DWH. Затем данные из Batch layer попадают в Serving layer, где находится витрина данных. В Real-time layer появляются представления Real-time View, которые попадают в Serving layer и к которым могут обращаться аналитики.

У Lambda-архитектуры есть свой минус: нам необходимо дублировать логику в оба потока обработки данных. Если нам не нужна пакетная обработка, мы можем убрать её из архитектуры.

<img width="1300" height="590" alt="image" src="https://github.com/user-attachments/assets/c7b9b499-f691-4db6-a181-5509fcbddd25" />

# **Kappa-архитектура**

Kappa-архитектура — это архитектура только потоковой обработки данных. При этом есть возможность сохранять данные из Serving layer в долговременное хранилище.

<img width="1295" height="500" alt="image" src="https://github.com/user-attachments/assets/f65a2bfe-008d-4708-83ab-db940f316921" />

## Подходы к проектированию DWH

В зависимости от наличия центрального слоя существует два основополагающих подхода:

**DWH** – это корпоративное централизованное хранилище данных

# **DWH по Инмону**

-Проектирование ХД модели “сверху вниз”.

-Тщательный анализ бизнеса в целом.

-Выявление бизнес-областей.

-Определение ключевых бизнес-сущностей.

-Определение их характеристик (атрибутов) и связей между ними.

В результате анализа появляется понимание, какие сущности участвуют в бизнес-процессах и как они взаимодействуют друг с другом.

**Пример DWH по Инмону**

<img width="1388" height="772" alt="image" src="https://github.com/user-attachments/assets/6c151adc-437f-461c-82f2-10d0a1024325" />

**Преимущества:**

-«Единая версия правды».

-Отсутствие противоречивости в данных.

-Детальный слой содержит проекцию бизнес-процессов.

-Легкость поддержки при увеличении количества источников.

**Недостатки:**

-Сложность в проектировании, требуется высококлассная команда.

-Долгая реализация на первоначальном этапе анализа бизнеса.

# **DWH по Кимбаллу**

DWH по Кимбаллу – это копия транзакционных данных, специально структурированных для запроса и анализа в виде витрин данных. Хранилище по Кимбаллу можно назвать коллекцией витрин данных (отчетов).

-Проектирование снизу вверх.

-Анализ потребностей – определение необходимых отчетов.

-Анализ источников – идентификация доступных данных.

-Проектирование витрины под конкретного потребителя.

-Преобразование первичных данных из источников в витрины.

**Пример DWH по Кимбаллу**

<img width="1382" height="772" alt="image" src="https://github.com/user-attachments/assets/91b35343-d8b9-46c0-b618-b7f48f7594c4" />

**Преимущества:**

-Быстрый эффект.

-Достаточно поэтапного анализа бизнес-областей.

-Не требуется высококвалифицированных специалистов (на старте).

**Недостатки:**

-Высокая стоимость поддержки новых источников.

-Отсутствие стандартизации показателей (в каждой витрине может быть свой алгоритм).

# SCD

**SCD [Slowly Changing Dimensions]**

## **SCD 0**

**SCD 0** — заключается в том, что данные после первого попадания в таблицу далее никогда не изменяются. Этот метод практически никем не используется, т.к. он не поддерживает версионности. Он нужен лишь как нулевая точка отсчета для методологии SCD. По сути, вообще не SCD. Таблица, которая хранит пол родственников Дональда Дака - женский, мужской, не определено. Она также не требует ведения истории.

## **SCD 1**

**SCD 1** — это обычная перезапись старых данных новыми. В чистом виде этот метод тоже не содержит версионности и используется лишь там, где история фактически не нужна.

Пример: паспортные данные изменились и были перезаписаны

## **SCD 2**

**SCD 2** - есть два столбца. Первый столбец с датой, когда запись начала действовать. Вторая дата ставится 9999-01-01. Значит, что строка имеет актуальные данные. При обновлении данных, 9999-01-01 меняется на текущую дату и строка становится уже исторической. При этом новые данные появляются на следующей строке. Смотри пример

Пример:

| ID | Name           | Number | Team   | Date_start  | Date_end    |
|----|----------------|--------|--------|-------------|-------------|
| 1  | Marc Marquez   | 93     | Honda  | 2013-11-08  | 9999-01-01  |
| 2  | Valentino Rossi | 46    | Yamaha | 2010-11-07  | 9999-01-01  |
| 3  | Dani Pedrosa   | 26     | Honda  | 2014-11-08  | 2018-01-11  |
| 4  | Jorge Lorenzo  | 99     | Ducati | 2017-01-01  | 2019-01-01  |
| 5  | Jorge Lorenzo  | 99     | Honda  | 2019-01-02  | 9999-01-01  |

## **SCD 3**

**SCD 3** — В самой записи содержатся дополнительные поля для предыдущих значений атрибута. При получении новых данных, старые данные перезаписываются текущими значениями.

Пример:

| ID | Name           | Num | Previous_team | Current_team | Date_start  |
|----|----------------|-----|---------------|--------------|-------------|
| 1  | Marc Marquez   | 93  | NULL          | Honda        | 2013-11-08  |
| 2  | Valentino Rossi| 46  | NULL          | Yamaha       | 2010-11-07  |
| 3  | Dani Pedrosa   | 26  | NULL          | Honda        | 2014-11-08  |
| 4  | Jorge Lorenzo  | 99  | Ducati        | Honda        | 2019-01-02  |

## **SCD 4**

История изменений содержится в отдельной таблице: основная таблица всегда перезаписывается текущими данными с перенесением старых данных в другую таблицу. Обычно этот тип используют для аудита изменений или создания архивных таблиц.

Дальше есть еще 5 и 6 версии, но они являются уже просто комбинациями из выше перечисленных. Шарить за них не нужно. Да и о них мало кто знает вообще.

## NoSQL хранилища данных

Реляционные базы данных (SQL) долгое время были основным инструментом для хранения данных. 
Они хорошо справлялись с задачами, где данные организованы в таблицы с четкой структурой, например, в бухгалтерии, управлении запасами, и прочих бизнес-приложениях. 

**Структура SQL баз данных обеспечивает:**

- **Целостность данных:** строгие правила помогают избежать ошибок и дублирования данных.

- **Возможность сложных запросов:** с помощью языка SQL можно получать сложные выборки данных из нескольких таблиц.

Со временем стало ясно, что у реляционных баз данных есть некоторые ограничения, особенно в условиях стремительного роста объемов данных и увеличения разнообразия типов данных. 

**Вот несколько основных проблем:**

- **Масштабируемость:** Традиционные SQL базы данных не всегда хорошо справляются с горизонтальным масштабированием (увеличением числа серверов).

- **Гибкость схемы:** В реляционных базах данных структура таблиц жестко определена, что усложняет работу с данными, структура которых часто меняется.

- **Производительность:** При работе с очень большими объемами данных, запросы могут становиться медленными.

С появлением новых технологий и ростом популярности веб-приложений, социальных сетей и мобильных приложений возникли **новые требования к базам данных:**

- **Большие данные:** Необходимость обрабатывать и хранить огромные объемы данных.

- **Разнообразие данных:** Различные типы данных (тексты, изображения, видео, JSON документы и т.д.).

- **Гибкость:** Быстрая адаптация под изменяющиеся потребности бизнеса.

Здесь на сцену выходят NoSQL базы данных, которые были разработаны для удовлетворения этих новых требований. NoSQL (от англ. not only SQL — «не только SQL») — обозначение широкого класса разнородных систем управления базами данных, появившихся в конце 2000-х — начале 2010-х годов и существенно отличающихся от традиционных реляционных СУБД. Уже само название заявляет, что управлять данными можно не только с помощью Structured Query Language (SQL), т. е. языка структурированных запросов.

NoSQL предлагает несколько важных преимуществ - в противовес недостаткам реляционных баз данных:

- **Масштабируемость:** Легко масштабируются горизонтально, распределяя данные по множеству серверов.

- **Гибкость схемы:** Нет жесткой структуры, что позволяет хранить разнородные данные и изменять структуру данных на лету.

- **Высокая производительность:** Оптимизированы для обработки больших объемов данных и высоких нагрузок.

**Основные типы NoSQL баз данных и их применение:**

- **Документные базы данных** (например, MongoDB): Хранят данные в виде документов (JSON), что удобно для работы с неструктурированными данными.

- **Графовые базы данных** (например, Neo4j): Используются для работы с сильно связанными данными, такими как социальные графы.

- **Ключ-значение хранилища** (например, Redis): Простой и быстрый способ хранения пар ключ-значение.

- **Колоночные базы данных** (например, Cassandra ): Хорошо подходят для аналитики и работы с большими объемами данных.

Появление NoSQL баз данных стало ответом на изменившиеся требования к обработке и хранению данных в современных приложениях. Это позволило компаниям более эффективно управлять своими данными и адаптироваться к быстро меняющимся условиям бизнеса.

Попробуем "четко" определить NoSQL базы данных следующим образом: базы данных, которые жертвуют атомарностью и согласованностью ради масштабируемости и доступности

Как мы выяснили ранее с развитием интернета и ростом количества пользователей, объем данных, с которыми приходится работать, значительно увеличился. Стало очевидно, что для эффективной обработки этих данных необходимо еще и распределять их по множеству серверов, находящихся в разных географических зонах.

А с увеличением числа узлов в распределенной системе обеспечивать согласованность данных становится все сложнее. Когда данные реплицируются на нескольких узлах, необходимо, чтобы изменения в данных были синхронизированы, что может вызвать задержки и конфликты.

Вместе с тем, как возросшие объемы данных повышают требования к хранению, и современные приложения требуют высокой доступности и надежности. Пользователи ожидают, что сервисы будут работать 24/7 без простоев. Для этого системы должны быть устойчивыми к сбоям, что подразумевает возможность продолжать работу даже при отказе отдельных компонентов или при нарушениях в сетевом соединении.

Именно эти вызовы и привели к формулировке теоремы CAP.

В 2000 году Эрик Брюер (Eric Brewer), профессор компьютерных наук в Калифорнийском университете в Беркли, на конференции PODC (Principles of Distributed Computing) представил свои идеи о том, что распределенная система не может одновременно обеспечивать все три свойства — согласованность, доступность и устойчивость к разделению. Позднее эти идеи были формализованы как теорема CAP.

Теорема CAP утверждает, что в любой распределенной системе возможно обеспечить только два из трех свойств одновременно:

- **Согласованность (Consistency):** Все узлы в системе имеют одинаковые данные в любой момент времени.

- **Доступность (Availability):** Каждый запрос к системе получает ответ (не обязательно успешный) в течение разумного времени.

- **Устойчивость к разделению (Partition Tolerance):** Система продолжает функционировать, несмотря на разделение сети, которое может приводить к тому, что сообщения между узлами теряются или задерживаются.

Как это относится к NoSQL и к нашей теме? Очень просто - согласно теореме, система может гарантировать только два из этих свойств одновременно. Это важно для понимания выбора архитектуры NoSQL баз данных, поскольку разные базы данных оптимизируют разные комбинации этих свойств. 

<img width="927" height="468" alt="image" src="https://github.com/user-attachments/assets/68a3f12c-2b2e-4ec6-bd0e-38c4d4a92eda" />

**Основные дистрибутивы NoSQL баз данных**

В скобках у примеров указано какие свойства обеспечивает та или иная СУБД.

**1. MongoDB (CP)**

<img width="1024" height="276" alt="image" src="https://github.com/user-attachments/assets/5655ba27-e4d5-4b9c-844a-964d64407080" />

Одна из самых популярных NoSQL баз данных, использующая JSON-подобные документы для хранения данных.

- Преимущества: MongoDB хорошо масштабируется и поддерживает горизонтальное масштабирование.

- Пример использования: eBay использует MongoDB для управления несколькими аспектами своего бизнеса, включая обработку данных о пользователях и транзакциях.

- Масштаб: Благодаря гибкости и возможности горизонтального масштабирования, MongoDB помогает eBay эффективно обрабатывать большие объемы данных, обеспечивая высокую производительность и доступность

- Согласованность и устойчивость к разделению: MongoDB предпочитает быть согласованной и устойчивой к разделению, жертвуя доступностью - при возникновении сетевых проблем, она может временно приостановить возможность записи до восстановления соединения, чтобы сохранить согласованность данных.

- Применение: Подходит для приложений, где важно, чтобы данные были актуальными и доступными, например, в e-commerce или социальных сетях.

**2. Cassandra (AP)**

<img width="1500" height="303" alt="image" src="https://github.com/user-attachments/assets/ba079972-6168-4884-bd23-9d4be395f5f8" />

Распределенная база данных, спроектированная для обработки больших объемов данных на нескольких серверах без единой точки отказа.

- Преимущества: Обеспечивает высокую доступность и отказоустойчивость, основана на модели данных ключ-значение.

- Пример использования: Netflix использует Apache Cassandra для хранения и управления метаданными своего видеоконтента.

- Масштаб и ценность: Cassandra обеспечивает высокую доступность и устойчивость к отказам, что критически важно для Netflix, учитывая огромный объем данных и необходимость бесперебойного предоставления сервиса пользователям по всему миру.

- Доступность и устойчивость к разделению: Cassandra оптимизирована для обеспечения доступности и устойчивости к разделению, жертвуя строгой согласованностью. При чтении данных возможны незначительные несоответствия, которые будут исправлены со временем (eventual consistency).

- Применение: Подходит для приложений, требующих высокой доступности и масштабируемости, таких как системы мониторинга и интернет-сервисы.

**3. Redis(CP)**

<img width="1700" height="403" alt="image" src="https://github.com/user-attachments/assets/c0f1a8cb-6a44-4afa-96d1-425968e727f1" />

Отличается высокой производительностью и используется для кэширования данных в памяти, хранения сеансов пользователей, реализации очередей сообщений и других задач, где требуется быстрый доступ к данным.

- Преимущества: Очень быстрая и эффективная работа с данными благодаря хранению в оперативной памяти.

- Пример использования: Twitter использует Redis для кэширования данных и управления очередями сообщений.

- Масштаб и ценность: Высокая производительность Redis позволяет Twitter быстро обрабатывать миллионы запросов в секунду, обеспечивая своевременную доставку данных пользователям.

- Согласованность и устойчивость к разделению: Redis, особенно в кластерах с репликацией, может быть настроен на обеспечение согласованности и устойчивости к разделению, жертвуя доступностью в случае разделения сети.

- Применение: Часто используется для кэширования данных и управления сессиями, где важна высокая производительность и согласованность данных.

Каждый из этих дистрибутивов NoSQL баз данных имеет свои сильные стороны и лучше всего подходит для определенных типов задач и данных. Выбор конкретного дистрибутива зависит от ваших требований к объему данных, структуре данных, необходимости в масштабируемости и производительности. А так же от приоритетов вашего приложения: необходимость высокой доступности, строгой согласованности или устойчивости к разделению сети.

Помните архитектуру ACID - для SQL? Очевидно, ей нет места среди NoSQL решений. Здесь главенствует BASE - в следующем шаге немного о ней.

**Архитектура BASE**

BASE — это акроним, обозначающий принципы, используемые для проектирования распределенных систем и баз данных, которые делают упор на доступность и устойчивость к отказам, жертвуя строгой согласованностью. Концепция BASE (Basically Available, Soft state, Eventual consistency) возникла как альтернатива модели ACID, применяемой в традиционных реляционных базах данных.

**Компоненты BASE**

1. Basically Available (В основном доступная)

Описание: Система гарантирует доступность, то есть всегда отвечает на запросы, хотя ответ может быть не мгновенным или не всегда успешным.

Пример: В случае перегрузки система может вернуть менее точные данные или частичные результаты, но не "упадет".

2. Soft state (Мягкое состояние)

Описание: Состояние системы может изменяться со временем, даже без получения входных данных. Это связано с тем, что система не обязана немедленно поддерживать согласованное состояние во всех узлах.

Пример: Кэшированные данные могут постепенно обновляться или устаревать, и это не вызывает немедленного отказа системы.

3. Eventual consistency (Согласованность в конечном итоге)

Описание: Система гарантирует, что в конечном счете все узлы придут к согласованному состоянию, но не обязательно мгновенно. С течением времени и при отсутствии новых изменений данные будут согласованы.

Пример: В системе может быть момент, когда разные узлы имеют разные версии данных, но со временем эти версии синхронизируются.

**Примеры применения BASE**

BASE модель используется во многих современных распределенных системах, особенно в NoSQL базах данных, где требуется высокая доступность и масштабируемость. Рассмотрим несколько примеров:

**Cassandra**

Использование BASE: Cassandra предпочитает доступность и устойчивость к разделению сети, обеспечивая eventual consistency. Это позволяет системе оставаться доступной даже при отказах узлов или разделении сети.

**Amazon DynamoDB**

Использование BASE: DynamoDB обеспечивает высокую доступность и устойчивость к разделению, при этом данные в конечном итоге становятся согласованными. Это позволяет поддерживать непрерывную работу приложения, даже если некоторые узлы временно недоступны.

**MongoDB**

Использование BASE: MongoDB предлагает различные уровни согласованности, включая eventual consistency, чтобы обеспечить высокую производительность и доступность. Это позволяет системам работать даже при временных сбоях или перегрузках.

**Сравнение BASE и ACID**

**ACID (Atomicity, Consistency, Isolation, Durability) модель**, используемая в реляционных базах данных, ориентирована на строгое соблюдение согласованности и надежности транзакций:

- Atomicity (Атомарность): Транзакция выполняется полностью или не выполняется вовсе.

- Consistency (Согласованность): Транзакция переводит базу данных из одного согласованного состояния в другое.

- Isolation (Изоляция): Одновременные транзакции не влияют друг на друга.

- Durability (Долговечность): После завершения транзакции ее результаты сохраняются даже при сбоях системы.

**BASE модель**, напротив, делает упор на доступность и масштабируемость, жертвуя строгой согласованностью:

- Basically Available (В основном доступная): Система всегда доступна для обработки запросов.

- Soft state (Мягкое состояние): Состояние системы может изменяться со временем.

- Eventual consistency (Согласованность в конечном итоге): В конечном итоге все узлы придут к согласованному состоянию.

Архитектура BASE предоставляет альтернативный подход к проектированию распределенных систем, фокусируясь на высокой доступности и масштабируемости за счет строгой согласованности. Это делает BASE модель особенно полезной для современных NoSQL баз данных и приложений, требующих работы с большими объемами данных и высокой производительности. Понимание различий между BASE и ACID помогает выбрать подходящую модель в зависимости от требований конкретного приложения.

Вся эта теория отлично описывает "что-то очень нужное" , но для того, чтобы возникло понимание что именно, предлагаю в очередной раз воспользоваться примером. Условимся, что в этом уроке мы не пытаемся установить тот или иной инструмент, мы не учимся его использовать - мы попытаемся понять почему и зачем он необходим и что предшествовало его появлению. По-другому наша задача выглядит как заполнение пробелов в утверждении: "У нас появилось/случилось/стало ___________, поэтому нам теперь просто необходимо использовать _____________".

Так как с колоночные базами данных мы познакомились в главе с ClickHouse, предлагаю рассмотреть и понять такие виды NoSQL как Redis и MongoDB.

 Начнем с Redis.

Название СУБД произошло от аббревиатуры «Remote Dictionary Server» — ReDiS. Она является вспомогательной и выполняет функцию хранилища (Redis storage) и кэша для основной, центральной базы данных. Кэш (cache) — это временное хранилище, используемое для ускорения доступа к данным или ресурсам.

В качестве центральной могут использоваться, например, PostgreSQL.

Сейчас представим работу условного простейшего приложения. Как правило, оно размещено на сервере, имеет веб-интерфейс (сайт) и мобильное приложение - через которые пользователи и пользуются им. Также имеется сервер с основной базой данных PostgreSQL. Сценарий работы простой: Пользователи вносят данные - приложение формирует SQL-запрос на вставку данных INSERT. Пользователи хотят получить какие-то данные, приложение формирует запрос на SELECT и отправляет СУБД, та в свою очередь нужные данные отдает приложению и далее они отображаются у пользователей. Вот визуальная схема описанных процессов:

<img width="987" height="345" alt="image" src="https://github.com/user-attachments/assets/f6e563be-1afe-4a66-92d8-1f3f110271c7" />

Все вроде работает, все вроде хорошо, но пользователей стало большое количество и в какой-то момент просто одного сервера с БД становится недостаточно- он перегружается и не обеспечивает моментальный результат. Нет моментального результата - пользователи не довольны. Но при ближайшем рассмотрении выясняется что перегруз вашей БД обеспечен огромным количеством запросов похожих данных, да и вставляет это огромное количество людей примерно одинаковые данные. Пример из жизни: появляется важная новость и огромное количество людей переходят на источник ее разместивший. Ситуация касательно нашей схемы выглядит так:

<img width="1090" height="392" alt="image" src="https://github.com/user-attachments/assets/36a76250-7981-434d-9a14-05647360c7c1" />

Вот как раз для решения этой и подобных проблем используют кэш. А роль кэша выполняет Redis. В результате мы разгрузим основную БД от однотипных запросов, а Redis, в том числе и за счет того, что хранит данные в оперативной памяти сервера, обеспечит их обработку. Схематично это выглядит примерно так:

<img width="1159" height="562" alt="image" src="https://github.com/user-attachments/assets/f9f79c64-8534-4ae5-b430-12654c66add3" />

Ну очевидно, что при проектировании приложения неплохо было бы понимать и представлять к каким одинаковым "частям" данных пользователи могли бы обращаться очень часто. И будет правильным решением поместить эти "части" данных в кэш, и направлять пользователей сразу в него. А если их там нет, то обеспечьте получение из БД и поместите их в кэш, для дальнейшего использования.

Вот так примерно выглядит функционирование Redis. Напоминаю цель нашего урока - заполнить пропуски в начальном утверждении. Поэтому давайте сделаем это, хотя бы упрощенно: У нас в приложении появилось большое число запросов к одинаковым данным, есть очень "популярные" данные в БД, поэтому для оптимизации функционирования нам теперь просто необходимо использовать кэш, а в частности Redis.

А вот теперь настало время перейти MongoDB и про демонстрировать плюсы распределенных систем. Как мы помним, SQL база данных полезна наличием транзакций, но одновременно с этим данные хранящиеся в ней очень сложно разбить на части, хранящиеся на разных серверах - потому как это отменяет транзакции и сложно будет подтверждать соответствие ACID.  А при постоянно растущем объеме данных эта проблема SQL БД проявляется все более остро  - в этот момент и появились распределенные базы данных: без транзакций - но с возможностью распределять все данные хранящиеся в них по нескольким серверам объединенным в кластер( Кластер — группа компьютеров, серверов или процессоров, объединённых высокоскоростными каналами связи, представляющая с точки зрения пользователя единый аппаратный ресурс). Это позволяет сколь угодно много расширять место для хранения и причем делать это достаточно легко. 

Реализуем это визуально, добавив кластер из 3 серверов с MongoDB. (3 для наглядности - очевидно их может быть от 1 до бесконечности):

<img width="827" height="721" alt="image" src="https://github.com/user-attachments/assets/c3ac7058-6d8e-45d8-b176-2424222c476d" />

А что же за документы хранит в себе MongoDB?

Так или иначе когда придет время вы столкнетесь с этой базой данных в работе. Сейчас же, чтобы уяснить не только разницу в подходах хранения, но и в типах хранимых данных и методах обращения к ним, предлагаю провести параллели в виде сравнения с SQL.

Если реляционные базы данных хранят строки, то MongoDB хранит документы. В отличие от строк документы могут хранить сложную по структуре информацию. Документ можно представить как хранилище ключей и значений.  Вообще этот способ записи называется JSON (JavaScript Object Notation)  "Объектная нотация JavaScript" — это легковесный формат обмена данными, который легко читается и пишется человеком, а также легко парсится (анализируется и преобразуется в объект, пригодный для использования в программных приложениях) и генерируется машинами. Он основан на подмножестве языка программирования JavaScript, но является независимым от языка.

Пример одновременно и документа из MongoDB и JSON:

```
{
  "name": "Иван Иванов",
  "age": 25,
  "email": "ivanov@mymail.tu",
}
```

JSON включают пары "ключ-значение", заключенные в фигурные скобки {}.

В нашем примере ключи это: name, age, email.

Значения соответственно: Иван Иванов, 25, ivanov@mymail.tu.

Главное уловить суть записи: этих пар в JSON и в документе MongoDB может быть сколь угодно много, и документы не строго типизированы.

Ключ представляет простую метку, с которым ассоциировано определенный кусок данных. Однако при всех различиях есть одна особенность, которая сближает MongoDB и реляционные базы данных. В реляционных СУБД встречается такое понятие как первичный ключ. Это понятие описывает некий столбец, который имеет уникальные значения. В MongoDB для каждого документа имеется уникальный идентификатор, который называется _id. И если явным образом не указать его значение, то MongoDB автоматически сгенерирует для него значение.

Если в традиционном мире SQL есть таблицы, то в мире MongoDB есть коллекции. И если в реляционных БД таблицы хранят однотипные жестко структурированные объекты, то в коллекции могут содержать самые разные объекты, имеющие различную структуру и различный набор свойств.

Отсутствие жесткой схемы базы данных и в связи с этим потребности при малейшем изменении концепции хранения данных создавать эту схему заново значительно облегчают работу с базами данных MongoDB и дальнейшим их масштабированием.

Но, даже учитывая все недостатки традиционных баз данных и достоинства MongoDB, важно понимать, что задачи бывают разные и методы их решения бывают разные. В какой-то ситуации MongoDB действительно улучшит производительность вашего приложения, например, если надо хранить сложные по структуре данные. В другой же ситуации лучше будет использовать традиционные реляционные базы данных. Кроме того, можно использовать смешанный подход: хранить один тип данных в MongoDB, а другой тип данных - в традиционных БД.

Давайте в заключении просто вспомним одну из  наших таблиц из темы PostgreSQL и посмотрим, как бы выглядело её создание и наполнение в MongoDB.

Создаем и наполняем таблицу с должностями в PostgreSQL:

```
--создаем таблицу "positions":
CREATE TABLE positions (
    id SERIAL PRIMARY KEY,
    title VARCHAR(100),
    salary INT
);

--вставляем данные в таблицу:
INSERT INTO positions (title, salary) VALUES
    ('Программист', 1500),
    ('Юрист', 700),
    ('HR', 700),
    ('Дизайнер', 700),
    ('Маркетолог', 500),
    ('Data Engineer', 3000);

--выводим все данные из таблицы:
SELECT * FROM positions;
```

Создание коллекции в MongoDB обычно происходит автоматически при добавлении первого документа в нее. Если вы пытаетесь добавить документ в коллекцию, которая еще не существует, MongoDB автоматически создаст эту коллекцию для вас.

Вот как выглядит вставка данных в MongoDB:

```
// вставляем документы в коллекцию "positions":
db.positions.insertMany([
    { title: 'Программист', salary: 1500 },
    { title: 'Юрист', salary: 700 },
    { title: 'HR', salary: 700 },
    { title: 'Дизайнер', salary: 700 },
    { title: 'Маркетолог', salary: 500 },
    { title: 'Data Engineer', salary: 3000 }
]);

// извлекаем все документы из коллекции:
db.positions.find({});
```

Результат вывода строк в PostgreSQL мы уже неоднократно видели, давайте посмотрим на результат извлечения документов  из коллекции MongoDB:

```
{ "_id": ObjectId("60bde231fb318b7d70e87b9a"), "title": "Программист", "salary": 1500 }
{ "_id": ObjectId("60bde231fb318b7d70e87b9b"), "title": "Юрист", "salary": 700 }
{ "_id": ObjectId("60bde231fb318b7d70e87b9c"), "title": "HR", "salary": 700 }
{ "_id": ObjectId("60bde231fb318b7d70e87b9d"), "title": "Дизайнер", "salary": 700 }
{ "_id": ObjectId("60bde231fb318b7d70e87b9e"), "title": "Маркетолог", "salary": 500 }
{ "_id": ObjectId("60bde231fb318b7d70e87b9f"), "title": "Data Engineer", "salary": 3000 }
```

Вот и уникальный идентификатор документа _id, о котором упоминалось выше.

Наш пример содержит одинаковые документы - из-за чего может сложиться ошибочное впечатление о том, что отличий в хранении с PostgreSQL то и нет, но давайте добавим к любому документу из коллекции еще атрибутов, чего нельзя было бы сделать в SQL не изменив таблицу целиком:

```
db.positions.updateOne(
    { title: "Программист" }, // Условие выбора документа (то куда добавим)
    { $set: { department: "IT", location: "Remote" } } // Новые атрибуты для добавления
);
```

 Теперь один из документов будет длиннее остальных - MongoDB позволяет это, а для PosgreSQL это невыполнимая задача (это равносильно разному количеству разных столбцов в каждой строке).

Вот результат того же запроса на извлечение всех документов из коллекции:

```
{ 
  "_id": ObjectId("60bde231fb318b7d70e87b9a"), 
  "title": "Программист", 
  "salary": 1500, 
  "department": "IT", 
  "location": "Remote" 
}
{ 
  "_id": ObjectId("60bde231fb318b7d70e87b9b"), 
  "title": "Юрист", 
  "salary": 700 
}
{ 
  "_id": ObjectId("60bde231fb318b7d70e87b9c"), 
  "title": "HR", 
  "salary": 700 
}
{ 
  "_id": ObjectId("60bde231fb318b7d70e87b9d"), 
  "title": "Дизайнер", 
  "salary": 700 
}
{ 
  "_id": ObjectId("60bde231fb318b7d70e87b9e"), 
  "title": "Маркетолог", 
  "salary": 500 
}
{ 
  "_id": ObjectId("60bde231fb318b7d70e87b9f"), 
  "title": "Data Engineer", 
  "salary": 3000 
}
```

У первого документа число атрибутов отличается. Как и ожидалось.

Надеюсь, что благодаря этому уроку, не вдаваясь в подробности синтаксиса и выполнения обращений к СУБД у вас сложилось  представление о некоторых представителях NoSQL баз данных. Запросы в примерах предельно простые, чтобы можно было отследить различия буквально "читая" их. И узнать,что данные можно хранить не тривиальными таблицами, а в виде JSON.

Ну и конечно цель урока - заполнить утверждение: У нас появляется все больше пользователей, что приводит к увеличению объема неструктурированных данных, поэтому нам теперь просто необходимо использовать MongoDB для эффективного и легкого масштабирования и обработки растущего количества информации.
