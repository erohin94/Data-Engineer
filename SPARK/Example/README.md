## Apache Spark

Spark - фреймворк для работы с большими данными. Если данные не вмещаются на один компьютер. То можем посчитать их на кластере - на нескольких серверах, распределенно и паралельно. 

Spark работает в оперативке. 

Spark разбивает данные на кусочки (партиции) и распределяет по серверам. И каждый сервер считает свой кусок данных.

Пример:

Есть например файл `1GB` (csv, text, parquet или любой другой). Загружаем файл в компьютер, на котором есть pandas. Делаем трансформации (join, фильтрацию и тд) и сохраняем результат. Получаем агрегационный файл размером  `50МБ`. Один компьютер справился.

<img width="600" height="288" alt="image" src="https://github.com/user-attachments/assets/64bc8d00-bbae-4633-a60c-8fdfc25d9b73" />

Но может быть такое, что файл весит `100GB` и у нас нет столько ресурсов (оперативки, жесткого диска, памяти и тд). Поэтому pandas не сможет посчитать данный файл, так как нет мощностей и всего один компьютер. Тоесть не можем распаралелить и отдать часть расчетов другому компьютеру.

<img width="596" height="264" alt="image" src="https://github.com/user-attachments/assets/551f8ef5-6a95-4401-9160-290f6a632950" />

Поэтому есть Spark. Например есть файл размером `100GB` который spark условно делит на куски по `1GB` (базово делит на 128 МБ, но поделили по 1GB чтобы было удобнее считать). Каждый кусочек называется партиция, эта партиция летит на свой сервер (машину). И каждый сервер начинает обрабатывать этот маленький кусок (`1GB`). На серваке может быть несколько ядер, слотов оперативной памяти, жестких дисков. Все это обрабатывается (джоин, фильтр и тд). 

Если происходит джоин, то эти партици бегают из одного сервера, в другой. Где то собираются, где то фильтруются, убираются и тд (такая операция называется shuffle).

Далее когда spark говорим сохранить, то он сохраняет все эти файлы например в формате `txt` или может сохранить в S3, Hadoop, Greenplum. Тоесть отдали серверам посчитать, они посчитали и сохраняем на диск.

<img width="652" height="352" alt="image" src="https://github.com/user-attachments/assets/29165ff1-f227-4c36-a52a-52ed5eab5f61" />

Есть сервера (шкаф с полками (компьютерами)). У одного сервера(компьютера) есть процесор у которого есть ядра, так же у сервера есть оперативка, жесткий диск. Когда сервера обрабатывают данные, на каждом сервере запускается конкретный Java процесс (executor - исполнитель). Каждый Java процесс берет определенное количество ядер и оперативки. То есть использует оперативку сервера и ядра процессора именно этого сервера, где он запускается. 

Например на одном сервере запускаем два executor, и каждый executor использует для работы 2 ядра процессора и 6GB оперативки. Файл который мы нарезали и разбили на куски - это RDD, куски данных внутри спарк которые он понимает. Когда происходит джоин, мы должы соединить, отсортировать, т.е перекинуть RDD с одного executor на другой - это называют shuffle. Чем больше shuffle, тем хуже. Это дорогостоящая операция. 

Так же есть еще один исполнитель который называется Driver. Это тоже Java процесс который потребляет память. Он не хранит в себе RDD, он просто управляет executor. Говорит кому что считать и что делать.

<img width="681" height="363" alt="image" src="https://github.com/user-attachments/assets/c47e27f2-c0f5-4877-ac88-cfbe75542e72" />

Внутри это происходит след образом. В Hadooop есть ресурс менеджер Yarn. Тоесть запускаем Spark, запускается Driver, который обращается к Hadoop Yarn. И говорит ему, мне нужно 3 executor и дай им по одному ядру и 1GB оперативки. Yarn это делает и создает 3 executor и выделяет им необходимые ресурсы. Можно задать ресурсы статически, то есть сказал 3 ядра и 3 гига так и будет. Но можно и динамически, то есть например если ты не пользуешься спарк, то он убирает количество экзекуторов. А когда пользуюсь увеличивать.

<img width="562" height="674" alt="image" src="https://github.com/user-attachments/assets/d7721c84-e653-4af9-b7bb-1218623e710b" />
