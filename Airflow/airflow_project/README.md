# Airflow проект

[Инструкция по установке Airflow](https://github.com/erohin94/Data-Engineer/blob/main/Airflow/README.md)

# Пример

Пример создадания DAG с одним оператором, далее добавится ещё один и будет видно как описывать зависимость. Таким образом получится первый небольшой пайплайн.

**Скелет DAG**

Планировщик Airflow ищет все возможные DAG по наличию инстанса(объект, который был создан на основе шаблона или класса) объекта DAG в модуле (по пути, указанному в конфигурационном файле).

![image](https://github.com/user-attachments/assets/46993d7f-ebdb-4699-9ef8-47d8971b2412)

DAG должен быть доступен при импорте модуля/пакета планировщиком, поэтому его необходимо определять в глобальном пространстве имён. 

Также у каждого DAG должен быть уникальный dag_id, именно его вы видно в списке всех DAG, когда заходим в панель управления Airflow.

[Ссылка на простой DAG](https://github.com/erohin94/Data-Engineer/blob/main/Airflow/airflow_project/dags/first_dag.py)

Класс DAG умеет работать с контекстным менеджером with. 

В коде создается инстанс класса DAG, передаем ему уникальный dag_id, расписание запусков и параметры по умолчанию через default_args. 

Параметры по умолчанию удобны, когда хотим одни и те же настройки передать всем операторам, входящим в DAG. Также можно задавать индивидуальные настройки для каждого оператора. Например, количество перезапусков в случае ошибок, retries, или таймаут перед повторным запуском, retry_delay. Параметр start_date также может быть у каждого оператора свой.

У нас с вами получился простой DAG с одним лишь оператором — PythonOperator. Этот оператор принимает на вход callable (функцию, исполняемый класс или lambda выражение). Каждый оператор должен иметь уникальный task_id и dag к которому он относится.

Функция random_dice случайным образом генерирует число от 1 до 6, и в случае если выпало нечетное число возбуждает исключение ValueError. Обратите внимание, что в default_args мы задали настройки для перезапуска операторов в случае ошибок — retries=2, также таймаут между повторами равен 10 секундам, retry_delay. Это как раз поможет вам понять как Airflow ведёт себя в случае появления ошибок при выполнении кода.

Написанный DAG следует разместить в папке dags или той папке которая указана в конфигурационном пути.

Так же необходимо убедиться, что запущен планировщик и веб-сервер. Именно планировщик отвечает за обнаружение новых DAG.

Первый способ — это просто проверить, запущен ли контейнер с планировщиком через Docker.

Открыть терминал и выполнить команду: ```docker ps```. Это выведет список всех запущенных контейнеров. Среди них можно увидеть контейнер с именем, содержащим scheduler, если контейнер с планировщиком запущен.

![image](https://github.com/user-attachments/assets/cbfae9e5-1e38-46d5-a04a-2a2e61366d8a)

Так же можно проверить через: Логи контейнера, Веб-интерфейс Airflow и тд.

Если всё прошло без ошибок, то в панели управления должны увидеть свой первый DAG:

![image](https://github.com/user-attachments/assets/23cb4e40-9cae-4494-90ea-cc68da4f8aa1)

**Запуск DAG**

Мы указали:

```schedule_interval = daily```

```start_date = 2024-12-25```

Что означает, что наш DAG будет запускаться ежедневно, начиная с 25 декабря 2024 года.

Внимание, как только активируете DAG, планировщик автоматически запустит выполнение за все прошедшие дни, начиная с даты, указанной в start_date.

Когда я пишу эти строки на календаре 11 января 2025 года. Это значит, что активировав DAG, планировщик запустит выполнение с 25 декабря до 10 января включительно. Запуск за 11 января будет запланирован в полночь 12-го января, т.е. после 11 января 2024 года и 23:59:59 часов. Совокупно будет 18 запусков:

14 удачных запусков

![image](https://github.com/user-attachments/assets/0d8d1ad0-d490-428b-b944-a0af8e39bf9a)

4 неудачных запуска. На скриншоте видно, что запуск за 30 декабря, 1,3,9 января был неудачным даже с учётом дополнительных двух попыток. Получается, что во всех 3 запусках (1 запуск стандартный + 2 попытки) выпало нечетное число.

![image](https://github.com/user-attachments/assets/3b0f4d19-404b-48ef-a91d-29f2da7d239c)

![image](https://github.com/user-attachments/assets/d906ae43-109f-4eca-9701-d2ea495a8984)

**Про start_date и execution_date**

В Apache Airflow есть 2 ключевые даты, которые нужно понимать.

*Start Date* ```start_date```

*Execution Date* ```execution_date```

*Start Date* это дата начала от которой следует начинать запускать DAG согласно расписания schedule_interval.

*Execution Date* это дата выполнения конкретного запуска. В примере выше у меня было 18 запусков. 18 запусков, а значит 18 execution_date, а именно:

Execution date можно получить, обратившись к контексту выполнения. Контекст можно получить, вызвав функцию ```get_current_context```. Для примера работы с ```execution_date``` я создал новый [DAG](https://github.com/erohin94/Data-Engineer/blob/main/Airflow/airflow_project/dags/first_dag_execution_date.py) по аналогии с предыдущим, но немного модифицировал код оператора.

*Контекст — это информация о том, в каком состоянии находится выполнение задачи в момент её выполнения. Он включает в себя данные, такие как:*

Информация о DAG и задаче:

```dag_id``` — идентификатор DAG.

```task_id``` — идентификатор задачи.

```execution_date``` — дата и время выполнения задачи.

```task_instance``` — объект, представляющий текущую задачу в контексте её выполнения.

Параметры выполнения:

```ds``` — строковое представление даты выполнения задачи в формате YYYY-MM-DD.

```ts``` — временная метка (timestamp) даты и времени в формате YYYY-MM-DDTHH:MM:SS.

Информация о DAG Run:

```dag_run``` — объект, представляющий текущий запуск DAG, включая дату и время его выполнения.

Таски будут падать через день, т.е. каждый нечетный день.

![image](https://github.com/user-attachments/assets/f5d07f3e-a582-474a-9bca-0f70ec7194c5)

**Зависимость тасков**

Прелесть любого workflow менеджера в умении формировать граф зависимостей между тасками и успешно его выполнять. В предыдущем примере рассмотрели пайплайн всего лишь с одним таском PythonOperator even_only. Но в реальных пайплайнах количество тасков может достигать огромных значений, добавим ещё один таск, и сделаем его зависимым от первого.

Я буду использовать DummyOperator, который ничего не делает. [DAG](https://github.com/erohin94/Data-Engineer/blob/main/Airflow/airflow_project/dags/dag_with_two_tasks.py)

Обратите внимание на последнюю строку:

```even_only >> dummy```

Это способ указать направление выполнения тасков и их зависимость. Если в UI открыть детали DAG и посмотреть графическое представление зависимостей, то видно:

![image](https://github.com/user-attachments/assets/8af6c346-0abe-4291-a635-a64035baba80)

Что означает, что dummy_task зависит от выполнения even_only. Этот же код можно записать в других вариациях:

```# dummy.set_upstream(even_only)```

```# even_only.set_downstream(dummy)```

```# dummy << even_only```

Используем вариант со стрелочками, т.к. они интуитивно понятны, направление стрелок указывает на порядок выполнения.

Если стартовать новый DAG, то часть запусков провалится (в нечетный день), а другая часть будет успешно выполнена (в четный день). Я специально выбрал такой пример, чтобы была возможность посмотреть в интерфейсе как выглядят ситуации с неудачными запусками пайплайнов, изучить статусы операторов.

Пример выполнения в нечетный день (9 января 2025):

![image](https://github.com/user-attachments/assets/09e6e19c-c773-4974-b441-6ea7b9ecbc0a)

Обратите внимание, что Airflow подкрашивает операторы в цвет, соответствующий статусу в легенде. Красный означает, что оператор even_only вернул ошибку, а оранжевый сигнализирует о том, что предшествующий таск (для dummy_task это even_only) не был успешно выполнен (upstream failed).

Важно помнить, что успешное выполнение пайплайна возможно только при условии, что все операторы завершились без ошибок.

В четных днях вы должны увидеть следующую картину:

![image](https://github.com/user-attachments/assets/2dcdef95-a914-43ca-b5b1-812e5b15622e)

**TaskFlow API**

В Apache Airflow 2.0 появился новый способ описания DAG и PythonOperator — TaskFlow API. TaskFlow API это синтаксический сахар, который делает код чище и проще для чтения. Во второй версии Apache Airflow были введены 2 декоратора: dag и task.

Давайте посмотрим как выглядит предыдущий код, переписанный на TaskFlow API: [DAG]()


