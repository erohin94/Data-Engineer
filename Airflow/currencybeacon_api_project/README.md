Попробую написать свой Operator и Hook.

Они будут нужны для взаимодействия с внешним API сервисом, хранящим курсы валют. Также буду использовать PostgreOperator для укладки полученных данных в таблицу, которую также будет создавать отдельным таском.

# **Про Hook**

В Airflow, **hook** — это объект, который используется для установления подключения и взаимодействия с внешними системами, такими как базы данных, облачные хранилища, API и другие сервисы. Хуки предоставляют интерфейсы для выполнения операций с этими системами, абстрагируя детали подключения и взаимодействия. Они помогают упростить доступ к данным и поддерживать безопасность, так как многие параметры подключения можно задать в одном месте.

**Примеры хуков в Airflow:**

`PostgresHook`: Используется для подключения и выполнения операций с базами данных PostgreSQL. Например, вы можете подключаться к базе данных, выполнять SQL-запросы и управлять транзакциями.

`HttpHook`: Используется для взаимодействия с внешними API через HTTP-запросы.

`S3Hook`: Используется для взаимодействия с хранилищем S3 в AWS. Вы можете загружать и скачивать файлы, создавать бакеты и другие операции.

**Как работают хуки:**

**Соединение:** Хуки получают данные подключения (логин, пароль, хост, порт и т.д.) из настроек соединений Airflow (в Admin -> Connections), для доступа к базам данных, API или другим системам.

**Методы:** Каждый хук предоставляет набор методов для выполнения операций с внешними системами, например, get_conn(), run() и другие. Например, для взаимодействия с базой данных можно использовать методы для выполнения SQL-запросов, загрузки данных и т.д.

**Повторное использование:** Хуки позволяют создавать общие логики взаимодействия с внешними системами, которые можно повторно использовать в различных тасках.

# **Описание проекта**

DAG будет выглядеть следующим образом:

**Здесь будет картинка------------------------------------------------------------**

В пайплайне 3 таска:

`create_table`, отвечает за создание таблицы в базе данных PostgreSQL

`get_rate`, собственный Operator для работы с API сервиса курсов валют

`insert_rate`, укладывает полученный курс в таблицу, созданную в таске create_table

-------------------------------------------------------------------------------------

**create_table**

Первый таск из пайплайна отвечает за создание таблицы, если её нет. В качестве базы данных используется PostgreSQL, можно поднять новый docker-образ базы:

[Ссылка для настройки PostgreSQL через Docker](https://github.com/erohin94/Data-Engineer/tree/main)

[Ссылка для настройки Airflow через Docker](https://github.com/erohin94/Data-Engineer/tree/main/Airflow)

В интерфейсе Airflow, в Admin → Connections необходимо обновить соединение postgres_default как показано на скрине:

![image](https://github.com/user-attachments/assets/51a5ea93-17a0-4e36-a9f7-28a06e909eaf)

Для подключения, передал в Admin → Connections следующие параметры из `docker-compose.yml` файла:

```
services:
  postgres:
    image: postgres:15
    restart: always
    container_name: postgres
    environment:
      POSTGRES_USER: test
      POSTGRES_PASSWORD: 1
      POSTGRES_DB: postgres
    ports:
      - "5432:5432"
    volumes:
      - ./postgres_data:/var/lib/postgresql/data
      

volumes:
  postgres_data:
```

где:

`Connection Id` : `postgres_default` (или любое другое имя для идентификации подключения)

`Connection Type` : `Postgres`

`Host` : `postgres` (это имя контейнера PostgreSQL, указанное в docker-compose.yml)

`Database` : postgres` (имя базы данных, как указано в переменной среды POSTGRES_DB)

`Login` : `test` (имя пользователя, указанное в переменной среды POSTGRES_USER)

`Password` : `1` (пароль, указанный в переменной среды POSTGRES_PASSWORD)

`Port` : `5432` (порт PostgreSQL)

Это соединение используется по умолчанию для всех Postgres операторов, безусловно можно создать новое и явно указывать его ID при создании оператора.

Для работы с Postgres в Apache Airflow есть `PostgresOperator`. Под капотом он использует библиотеку `psycopg2` для работы с базой. Именно его мы будем использовать в двух из трёх наших операторах:

`create_table`
`insert_rate`

`PostgresOperator` может принимать запрос строкой либо читать его из файла. Буду сспользовать второй вариант, т.к. он делает код более читабельным без смешивания SQL и Python. Пример оператора с запросом строкой:

```
sql_task = PostgresOperator(
    task_id='sql_task_id',
    postgres_conn_id='postgres_default',
    sql='SELECT foo FROM bar;',
)
```

Через указание пути до SQL файла:

```
sql_task = PostgresOperator(
    task_id='sql_task_id',
    postgres_conn_id='postgres_default',
    sql='sql/select_query.sql',
)
```

Выбираю второй вариант, поэтому необходимо подготовить SQL запрос создания таблицы и сохранить его в файл create_table.sql:

```
CREATE TABLE IF NOT EXISTS currency_exchange_rates (
    base VARCHAR(3) NOT NULL,
    currency VARCHAR(3) NOT NULL,
    rate NUMERIC(12, 3) NOT NULL,
    date DATE NOT NULL,
    UNIQUE (base, currency, date)
);
```

При каждом запуске DAG будет выполняться таск `create_table`, поэтому в SQL выражении есть конструкция `IF NOT EXISTS`, которая означает, что таблица должна быть создана ТОЛЬКО, если её нет. То есть при повторном выполнении этого таска Postgres проигнорирует этот запрос, т.к. таблица уже будет существовать.

Таблица `currency_exchange_rates`:

`base` — хранится код базовой валюты

`currency` — хранится код конвертируемой валюты

`rate` — обменный курс между `currency` и `base`, т.е. стоимость `base` в `currency`

`date` — дата

Свойство `UNIQUE` по трём столбцам необходимо, чтобы делать вставку через `UPSERT` (опишу далее). Если по какой-то причине таск с одной и той же датой будет запущен несколько раз нужно не допустить дублирования.

Итак, всё готово для создания первого оператора:

```
create_table = PostgresOperator(
    task_id='create_table_task',
    sql='sql/create_table.sql',
    postgres_conn_id='postgres_default',
)
```

Путь SQL файла необходимо указывать относительно директории, где лежит сам DAG. В данном случае папка sql лежит в одной директории с кодом DAGа. Аргумент `postgres_conn_id` можно не указывать, т.к. по умолчанию он будет равен `postgres_default`, но я предпочитаю явно это делать.

**get_rate**

Для таска `get_rate` напишем свой кастомный оператор, который будет тянуть данные из внешнего API. В качестве сервиса использую [currencybeacon](https://currencybeacon.com/).

Для работы с сервисом необходимо зарегистрироваться и получить API ключ. Ключ будет доступен сразу же после авторизации на сайте:

![Снимок](https://github.com/user-attachments/assets/533d9738-92a6-4ad4-ab60-e4159553cc1d)

`Operator` и `Hook` для работы с сервисом напишем позже, сейчас рассмотрим последний таск в нашем пайплайне — `insert_rate`.

**insert_rate**

Для таска `insert_rate` также будем использовать `PostgresOperator`. Его задача — добавить запись о курсе валют в базу данных после успешного выполнения предыдущего таска `get_rate`.






